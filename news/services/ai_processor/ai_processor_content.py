import json
import logging
from typing import Dict
from .ai_processor_base import AINewsProcessor
from news.models import RawArticle

logger = logging.getLogger(__name__)


class AIContentProcessor(AINewsProcessor):
    """–ú–æ–¥—É–ª—å –¥–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç—Ä–∏–º–æ–≤–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç—É"""

    def _categorize_article(self, raw_article: RawArticle) -> Dict:
        """AI –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü—ñ—è —Å—Ç–∞—Ç—Ç—ñ"""
        
        categories = {
            'ai': 'artificial intelligence, machine learning, neural networks, AI models, automation AI',
            'automation': 'business automation, RPA, workflow automation, process optimization, zapier',
            'crm': 'customer relationship management, sales automation, CRM systems, customer service',
            'seo': 'search engine optimization, digital marketing, SEO tools, search rankings, Google',
            'social': 'social media marketing, Facebook, Instagram, Twitter, social media automation',
            'chatbots': 'chatbots, conversational AI, virtual assistants, customer support bots',
            'ecommerce': 'online store, e-commerce platforms, Shopify, online retail, digital commerce',
            'fintech': 'financial technology, payments, cryptocurrency, digital banking, blockchain',
            'corporate': 'enterprise technology, business technology, corporate news, company updates',
            'general': 'technology news, tech industry, software development, programming'
        }
        
        # –ü—Ä–æ—Å—Ç–∏–π AI –ø—Ä–æ–º–ø—Ç –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü—ñ—ó
        content_for_analysis = f"{raw_article.title} {raw_article.summary}"
        
        prompt = f"""
        Analyze this article and determine the most appropriate category:
        
        Article: {content_for_analysis[:2000]}
        
        Categories: {json.dumps(categories)}
        
        Respond with just the category slug (e.g., "ai", "automation", etc.)
        """
        
        try:
            category_slug = self._call_ai_model(prompt, max_tokens=10).strip().lower()
            
            # –í–∞–ª—ñ–¥–∞—Ü—ñ—è –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó
            if category_slug not in categories:
                category_slug = 'general'
            
            # –í–∏–∑–Ω–∞—á–∞—î–º–æ –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç
            priority = 2  # –°–µ—Ä–µ–¥–Ω—ñ–π –∑–∞ –∑–∞–º–æ–≤—á–∞–Ω–Ω—è–º
            if any(word in content_for_analysis.lower() for word in ['breaking', 'urgent', 'major', 'launches']):
                priority = 3  # –í–∏—Å–æ–∫–∏–π
            elif 'google' in content_for_analysis.lower() or 'microsoft' in content_for_analysis.lower():
                priority = 3  # –í–∏—Å–æ–∫–∏–π –¥–ª—è –≤–µ–ª–∏–∫–∏—Ö –∫–æ–º–ø–∞–Ω—ñ–π
                
            return {
                'category': category_slug,
                'priority': priority,
                'keywords': categories[category_slug].split(', ')
            }
            
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü—ñ—ó: {e}")
            return {'category': 'general', 'priority': 2, 'keywords': []}
        
    def _clip_to_range(self, text: str, min_len: int = 2000, max_len: int = 3000) -> str:
        """–û–±—Ä—ñ–∑–∞—î —Ç–µ–∫—Å—Ç –¥–æ –¥—ñ–∞–ø–∞–∑–æ–Ω—É —Å–∏–º–≤–æ–ª—ñ–≤ —ñ–∑ –º'—è–∫–∏–º –∑—Ä—ñ–∑–æ–º –ø–æ –∫—Ä–∞–ø—Ü—ñ."""
        if not text:
            return ""
        t = text.strip()
        if len(t) > max_len:
            # —Å–ø—Ä–æ–±—É—î–º–æ –æ–±—Ä—ñ–∑–∞—Ç–∏ –ø–æ –∑–∞–∫—ñ–Ω—á–µ–Ω–Ω—é —Ä–µ—á–µ–Ω–Ω—è
            cut = t.rfind(". ", 0, max_len)
            if cut >= min_len:
                t = t[:cut+1]
            else:
                t = t[:max_len]
        return t

    def _extract_main_topic(self, title: str) -> str:
        """–í–∏—Ç—è–≥—É—î –æ—Å–Ω–æ–≤–Ω—É —Ç–µ–º—É –∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –¥–ª—è fallback –∑–∞–≥–æ–ª–æ–≤–∫—ñ–≤"""
        if not title:
            return "Technology"
            
        # –û—á–∏—â–∞—î–º–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –≤—ñ–¥ –∑–∞–π–≤–∏—Ö —Å–∏–º–≤–æ–ª—ñ–≤
        clean_title = title.strip()
        
        # –í–∏—Ç—è–≥—É—î–º–æ –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞
        tech_keywords = {
            'ai': 'AI', 'artificial intelligence': 'AI', 'machine learning': 'ML',
            'automation': 'Automation', 'docker': 'Docker', 'kubernetes': 'Kubernetes',
            'google': 'Google Tech', 'microsoft': 'Microsoft Tech', 'apple': 'Apple Tech',
            'openai': 'OpenAI', 'chatgpt': 'ChatGPT', 'blockchain': 'Blockchain',
            'cryptocurrency': 'Crypto', 'fintech': 'FinTech', 'startup': 'Startup',
            'security': 'Security', 'privacy': 'Privacy', 'cloud': 'Cloud',
            'api': 'API', 'software': 'Software', 'development': 'Development'
        }
        
        title_lower = clean_title.lower()
        
        # –®—É–∫–∞—î–º–æ –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞
        for keyword, topic in tech_keywords.items():
            if keyword in title_lower:
                return topic
                
        # –Ø–∫—â–æ –Ω–µ –∑–Ω–∞–π—à–ª–∏ –∫–ª—é—á–æ–≤–∏—Ö —Å–ª—ñ–≤, –±–µ—Ä–µ–º–æ –ø–µ—Ä—à—ñ —Å–ª–æ–≤–∞
        words = clean_title.split()[:3]  # –ü–µ—Ä—à—ñ 3 —Å–ª–æ–≤–∞
        if words:
            return ' '.join(words)
            
        return "Technology"

    def _normalize_lengths(self, content_data: Dict) -> Dict:
        """–ó–∞–±–µ–∑–ø–µ—á—É—î –¥–æ–≤–∂–∏–Ω—É 2000‚Äì3000 —Å–∏–º–≤–æ–ª—ñ–≤ –¥–ª—è summary_*."""
        for lang in ["en", "uk", "pl"]:
            key = f"summary_{lang}"
            content_data[key] = self._clip_to_range(content_data.get(key, ""), 2000, 3000)
        return content_data
    
    def _clean_json_response(self, response: str) -> str:
        """–û—á–∏—â–∞—î JSON –≤—ñ–¥–ø–æ–≤—ñ–¥—å –≤—ñ–¥ markdown –±–ª–æ–∫—ñ–≤ —Ç–∞ –∑–∞–π–≤–æ–≥–æ —Ç–µ–∫—Å—Ç—É"""
        
        if not response or not response.strip():
            return "{}"
        
        # –í–∏–¥–∞–ª—è—î–º–æ markdown –±–ª–æ–∫–∏
        if response.startswith('```json'):
            response = response[7:]
        if response.startswith('```'):
            response = response[3:]
        if response.endswith('```'):
            response = response[:-3]
        
        # –û—á–∏—â–∞—î–º–æ –ø—Ä–æ–±—ñ–ª–∏
        response = response.strip()
        
        # –ó–ù–ê–•–û–î–ò–ú–û –¢–Ü–õ–¨–ö–ò JSON –ß–ê–°–¢–ò–ù–£
        try:
            # –®—É–∫–∞—î–º–æ –ø–æ—á–∞—Ç–æ–∫ JSON
            start = response.find('{')
            if start == -1:
                self.logger.warning(f"[JSON] –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –ø–æ—á–∞—Ç–æ–∫ JSON –≤ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ: {response[:200]}...")
                return "{}"
                
            # –†–∞—Ö—É—î–º–æ –¥—É–∂–∫–∏ —â–æ–± –∑–Ω–∞–π—Ç–∏ –∫—ñ–Ω–µ—Ü—å JSON
            brace_count = 0
            end = start
            in_string = False
            escape_next = False
            
            for i, char in enumerate(response[start:], start):
                if escape_next:
                    escape_next = False
                    continue
                    
                if char == '\\':
                    escape_next = True
                    continue
                    
                if char == '"' and not escape_next:
                    in_string = not in_string
                    continue
                    
                if not in_string:
                    if char == '{':
                        brace_count += 1
                    elif char == '}':
                        brace_count -= 1
                        if brace_count == 0:
                            end = i + 1
                            break
            
            # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ —Ç—ñ–ª—å–∫–∏ JSON —á–∞—Å—Ç–∏–Ω—É
            json_part = response[start:end]
            
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —Ü–µ –≤–∞–ª—ñ–¥–Ω–∏–π JSON
            try:
                parsed = json.loads(json_part)
                self.logger.info(f"[JSON] –£—Å–ø—ñ—à–Ω–æ —Ä–æ–∑–ø–∞—Ä—Å–µ–Ω–æ JSON –∑ {len(parsed)} –ø–æ–ª—è–º–∏")
                return json_part
            except json.JSONDecodeError as e:
                self.logger.warning(f"[JSON] –ù–µ–≤–∞–ª—ñ–¥–Ω–∏–π JSON: {e}")
                self.logger.warning(f"[JSON] –ü—Ä–æ–±–ª–µ–º–Ω–∞ —á–∞—Å—Ç–∏–Ω–∞: {json_part[-200:]}")
                
                # –°–ø—Ä–æ–±—É—î–º–æ –≤–∏–ø—Ä–∞–≤–∏—Ç–∏ JSON, –æ–±—Ä—ñ–∑–∞–≤—à–∏ –¥–æ –æ—Å—Ç–∞–Ω–Ω—å–æ–≥–æ –≤–∞–ª—ñ–¥–Ω–æ–≥–æ –ø–æ–ª—è
                try:
                    # –®—É–∫–∞—î–º–æ –æ—Å—Ç–∞–Ω–Ω—ñ–π –≤–∞–ª—ñ–¥–Ω–∏–π –∑–∞–∫—Ä–∏–≤–∞—é—á–∏–π –¥—É–∂–∫–∏
                    last_valid_brace = json_part.rfind('}')
                    if last_valid_brace > 0:
                        # –î–æ–¥–∞—î–º–æ –∑–∞–∫—Ä–∏–≤–∞—é—á—É –¥—É–∂–∫—É
                        fixed_json = json_part[:last_valid_brace + 1]
                        parsed = json.loads(fixed_json)
                        self.logger.info(f"[JSON] –í–∏–ø—Ä–∞–≤–ª–µ–Ω–æ JSON, –æ–±—Ä—ñ–∑–∞–Ω–æ –¥–æ {len(parsed)} –ø–æ–ª—ñ–≤")
                        return fixed_json
                except:
                    pass
                
                # –Ø–∫—â–æ JSON –∑–æ–≤—Å—ñ–º –Ω–µ–≤–∞–ª—ñ–¥–Ω–∏–π, —Å–ø—Ä–æ–±—É—î–º–æ –∑–Ω–∞–π—Ç–∏ —Ö–æ—á–∞ –± —á–∞—Å—Ç–∏–Ω—É
                try:
                    # –®—É–∫–∞—î–º–æ –ø–µ—Ä—à–∏–π –≤–∞–ª—ñ–¥–Ω–∏–π JSON –æ–±'—î–∫—Ç
                    start = json_part.find('{')
                    if start >= 0:
                        # –®—É–∫–∞—î–º–æ –æ—Å—Ç–∞–Ω–Ω—é –∑–∞–∫—Ä–∏–≤–∞—é—á—É –¥—É–∂–∫—É
                        last_brace = json_part.rfind('}')
                        if last_brace > start:
                            partial_json = json_part[start:last_brace + 1]
                            # –î–æ–¥–∞—î–º–æ –∑–∞–∫—Ä–∏–≤–∞—é—á—ñ –¥—É–∂–∫–∏ –¥–ª—è –Ω–µ–¥–æ–ø–∏—Å–∞–Ω–∏—Ö –ø–æ–ª—ñ–≤
                            if not partial_json.strip().endswith('}'):
                                partial_json += '}'
                            parsed = json.loads(partial_json)
                            self.logger.info(f"[JSON] –í—ñ–¥–Ω–æ–≤–ª–µ–Ω–æ —á–∞—Å—Ç–∫–æ–≤–∏–π JSON –∑ {len(parsed)} –ø–æ–ª—è–º–∏")
                            return partial_json
                except:
                    pass
                
                # –û—Å—Ç–∞–Ω–Ω—è —Å–ø—Ä–æ–±–∞ - —Å—Ç–≤–æ—Ä–∏—Ç–∏ –º—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π JSON –∑ —Ç–∏–º —â–æ —î
                try:
                    # –®—É–∫–∞—î–º–æ —Ö–æ—á–∞ –± –∑–∞–≥–æ–ª–æ–≤–∫–∏
                    title_en_match = json_part.find('"title_en"')
                    if title_en_match > 0:
                        # –®—É–∫–∞—î–º–æ –∑–Ω–∞—á–µ–Ω–Ω—è title_en
                        start_quote = json_part.find('"', title_en_match + 10)
                        end_quote = json_part.find('"', start_quote + 1)
                        if start_quote > 0 and end_quote > start_quote:
                            title_en = json_part[start_quote + 1:end_quote]
                            
                            # –°—Ç–≤–æ—Ä—é—î–º–æ –º—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π JSON
                            minimal_json = f'{{"title_en": "{title_en}", "title_uk": "{title_en}", "title_pl": "{title_en}"}}'
                            parsed = json.loads(minimal_json)
                            self.logger.info(f"[JSON] –°—Ç–≤–æ—Ä–µ–Ω–æ –º—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π JSON –∑ {len(parsed)} –ø–æ–ª—è–º–∏")
                            return minimal_json
                except:
                    pass
                
                return "{}"
            
        except Exception as e:
            self.logger.error(f"[JSON] –ü–æ–º–∏–ª–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥—É JSON: {e}")
            return "{}"

    def _create_multilingual_content(self, raw_article: RawArticle, category_info: Dict, full_content: str = None) -> dict:
        """–°—Ç–≤–æ—Ä—é—î —Ç—Ä–∏–º–æ–≤–Ω–∏–π –û–†–ò–ì–Ü–ù–ê–õ–¨–ù–ò–ô –±—ñ–∑–Ω–µ—Å-–∞–Ω–∞–ª—ñ–∑ –∑ RSS (~1000‚Äì1200 —Å–∏–º–≤–æ–ª—ñ–≤)."""
        original_title = raw_article.title or ""
        # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ø–µ—Ä–µ–¥–∞–Ω–∏–π full_content –∞–±–æ –∫–æ–Ω—Ç–µ–Ω—Ç –∑ raw_article
        if full_content:
            content_to_use = full_content
        else:
            content_to_use = raw_article.content or raw_article.summary or ""
        
        # –î–∏–Ω–∞–º—ñ—á–Ω–∏–π –ª—ñ–º—ñ—Ç: –¥–æ 8–ö —Å–∏–º–≤–æ–ª—ñ–≤ (–±–µ–∑–ø–µ—á–Ω–æ –¥–ª—è Claude API + –ø—Ä–æ–º–ø—Ç)
        max_ai_content = min(len(content_to_use), 8000)
        content_for_ai = content_to_use[:max_ai_content]
        
        self.logger.info(
            f"[AI INPUT] –°—Ç–∞—Ç—Ç—è: {raw_article.title[:60]}...\n"
            f"   Full content: {len(content_to_use)} —Å–∏–º–≤–æ–ª—ñ–≤\n"
            f"   –ü–µ—Ä–µ–¥–∞—î–º–æ AI: {len(content_for_ai)} —Å–∏–º–≤–æ–ª—ñ–≤\n"
            f"   Source: {raw_article.source.name if raw_article.source else 'Unknown'}"
        )
        category = category_info["category"]

        # –ü—ñ–¥–≥–æ—Ç–æ–≤—É—î–º–æ –¥–∞–Ω—ñ –¥–ª—è –ø—Ä–æ–º–ø—Ç—É
        source_name = raw_article.source.name if raw_article.source else "Unknown Source"
        original_url = raw_article.original_url or ""
        
        main_prompt = f"""
You are LAZYSOFT's senior tech analyst. Your job is to ANALYZE and SYNTHESIZE information from tech articles for European SMB audience, NOT to translate or copy.

CRITICAL ANTI-PLAGIARISM RULES:
üö´ NEVER copy sentences from the original article
üö´ NEVER translate article text directly
üö´ NEVER use exact phrases even in quotes
‚úÖ ALWAYS analyze, interpret, and explain in YOUR OWN WORDS
‚úÖ ALWAYS add business context and SMB perspective
‚úÖ ALWAYS synthesize information into original analysis

ORIGINAL ARTICLE INFO:
Title: {original_title}
Source: {source_name}
Content to analyze: {content_for_ai}
Category: {category}

YOUR TASK:
1. READ and UNDERSTAND the article
2. EXTRACT key facts, technologies, companies mentioned
3. ANALYZE what this means for European SMBs
4. WRITE ORIGINAL analysis in your own words
5. CREATE unique business-focused titles that describe the news

TITLE REQUIREMENTS:
- Must be ORIGINAL, not copy of source title
- Format examples:
  * "–ù–æ–≤–∏–Ω–∏ –ø—Ä–æ [technology/company]: —â–æ –∫–∞–∂–µ [Source Name] –ø—Ä–æ [key point]"
  * "–û—Å—Ç–∞–Ω–Ω—ñ —Ä–æ–∑—Ä–æ–±–∫–∏ [topic]: –∞–Ω–∞–ª—ñ–∑ –≤—ñ–¥ [Source Name]"  
  * "[Source Name] –ø–æ–≤—ñ–¥–æ–º–ª—è—î –ø—Ä–æ [main point] - —â–æ —Ü–µ –æ–∑–Ω–∞—á–∞—î –¥–ª—è –±—ñ–∑–Ω–µ—Å—É"
- Include source name for credibility
- Describe WHAT the article discusses, not copy its title

CONTENT REQUIREMENTS (2000-3000 chars per language):
- Write as LAZYSOFT analyst, not as article translator
- Structure: 
  1. What happened (in your words)
  2. Key technologies/companies/numbers involved
  3. Why it matters for European SMBs
  4. Practical implications
- Use phrases like:
  * "–ó–∞ –¥–∞–Ω–∏–º–∏ [Source], ..."
  * "[Source Name] –ø–æ–≤—ñ–¥–æ–º–ª—è—î, —â–æ..."
  * "–ó–≥—ñ–¥–Ω–æ –∑ –∞–Ω–∞–ª—ñ–∑–æ–º –≤—ñ–¥ [Source], ..."
  * "–î–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è –ø–æ–∫–∞–∑—É—î..."
- Include specific facts but REPHRASE them
- Add LAZYSOFT perspective on automation opportunities

EXAMPLE OF ORIGINAL ANALYSIS:

Article: "Google AI Max Early Case Studies: Performance Analysis and Script"
Source: Search Engine Land

‚ùå BAD (copying):
"Google's AI Max combines Dynamic Search Ads and Performance Max. The script creates two tabs in your Sheet: AI Max Performance Max search term data with headlines, landing pages, and performance metrics..."

‚úÖ GOOD (original analysis):
"Search Engine Land –æ–ø—É–±–ª—ñ–∫—É–≤–∞–≤ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ Google AI Max, —â–æ –æ–±'—î–¥–Ω—É—î —Ç–µ—Ö–Ω–æ–ª–æ–≥—ñ—ó Dynamic Search Ads —Ç–∞ Performance Max. –ê–Ω–∞–ª—ñ–∑ —Ç—Ä—å–æ—Ö —Å–µ–∫—Ç–æ—Ä—ñ–≤ –≤–∏—è–≤–∏–≤ —Ü—ñ–∫–∞–≤—ñ –ø–∞—Ç–µ—Ä–Ω–∏: —Ç—É—Ä–∏—Å—Ç–∏—á–Ω–∏–π —Å–µ–∫—Ç–æ—Ä –ø–æ–∫–∞–∑–∞–≤ 22.5% –ø–µ—Ä–µ—Ç–∏–Ω—É –∑ —ñ—Å–Ω—É—é—á–∏–º–∏ –∑–∞–ø–∏—Ç–∞–º–∏, —â–æ –º–æ–∂–µ —Å–≤—ñ–¥—á–∏—Ç–∏ –ø—Ä–æ –ø–µ—Ä–µ—Ä–æ–∑–ø–æ–¥—ñ–ª —Ç—Ä–∞—Ñ—ñ–∫—É, —Ç–æ–¥—ñ —è–∫ —ñ–Ω–¥—É—Å—Ç—Ä—ñ—è –º–æ–¥–∏ –≤–∏—è–≤–∏–ª–∞ 81.3% –∞–±—Å–æ–ª—é—Ç–Ω–æ –Ω–æ–≤–∏—Ö –∑–∞–ø–∏—Ç—ñ–≤ - —Ü–µ —Å–ø—Ä–∞–≤–∂–Ω—è –º–æ–∂–ª–∏–≤—ñ—Å—Ç—å –¥–ª—è –∑—Ä–æ—Å—Ç–∞–Ω–Ω—è. –î–ª—è –ú–°–ü –æ—Å–æ–±–ª–∏–≤–æ —Ü—ñ–Ω–Ω–∏–º —î –∞–≤—Ç–æ–º–∞—Ç–∏–∑–æ–≤–∞–Ω–∏–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è Google Sheets, —è–∫–∏–π –¥–æ–∑–≤–æ–ª—è—î —à–≤–∏–¥–∫–æ –∞–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏ –µ—Ñ–µ–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å –∫–∞–º–ø–∞–Ω—ñ–π –±–µ–∑ —Ä—É—á–Ω–æ—ó —Ä–æ–±–æ—Ç–∏..."

VERIFICATION BEFORE RESPONDING:
‚òë Did I write in MY OWN WORDS?
‚òë Did I add business context original article doesn't have?
‚òë Would this pass plagiarism check?
‚òë Did I mention source but not copy their text?
‚òë Are titles ORIGINAL, not translated?
‚òë Did I include specific facts/numbers but rephrase them?

KEY TAKEAWAYS (3-5 bullet points per language):
- Extract SPECIFIC facts, numbers, technologies mentioned IN THIS ARTICLE
- NOT generic automation advice - only what THIS article discusses
- Example: "Google AI Max shows 81% new query discovery" (specific!)
- NOT: "AI can help businesses" (too generic!)

INTERESTING FACTS (2-3 per language):
- Statistics or data points FROM THE ARTICLE with source mention
- Industry trends DISCUSSED IN THE ARTICLE
- Company announcements or tech developments FROM ARTICLE CONTENT

IMPLEMENTATION STEPS (3-4 per language):
- Practical steps based on WHAT THE ARTICLE DISCUSSES
- If article about AI tool - steps to implement THAT tool
- If article about trend - steps to adapt to THAT trend
- Keep steps actionable and specific to article topic

OUTPUT JSON ONLY:
        {{
            "title_en": "Original analytical title mentioning source and key point",
            "title_uk": "–û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ—Ç–∏—á–Ω–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∑ –¥–∂–µ—Ä–µ–ª–æ–º",
            "title_pl": "Oryginalny tytu≈Ç analityczny ze ≈∫r√≥d≈Çem",
            
            "summary_en": "ORIGINAL analysis in your own words (2000-3000 chars) - NOT translation",
            "summary_uk": "–û–†–ò–ì–Ü–ù–ê–õ–¨–ù–ò–ô –∞–Ω–∞–ª—ñ–∑ —Å–≤–æ—ó–º–∏ —Å–ª–æ–≤–∞–º–∏ (2000-3000 —Å–∏–º–≤–æ–ª—ñ–≤) - –ù–ï –ø–µ—Ä–µ–∫–ª–∞–¥",
            "summary_pl": "ORYGINALNA analiza w≈Çasnymi s≈Çowami (2000-3000 znak√≥w) - NIE t≈Çumaczenie",
            
            "business_insight_en": "Unique business insight analyzing article findings for SMBs",
            "business_insight_uk": "–£–Ω—ñ–∫–∞–ª—å–Ω–∏–π –±—ñ–∑–Ω–µ—Å-—ñ–Ω—Å–∞–π—Ç –∑ –∞–Ω–∞–ª—ñ–∑–æ–º –¥–ª—è –ú–°–ü",
            "business_insight_pl": "Unikalny wglƒÖd biznesowy z analizƒÖ dla M≈öP",
            
            "business_opportunities_en": "LAZYSOFT perspective on automation opportunities (300-500 chars)",
            "business_opportunities_uk": "–ü–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–∞ LAZYSOFT —â–æ–¥–æ –º–æ–∂–ª–∏–≤–æ—Å—Ç–µ–π –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü—ñ—ó (300-500 —Å–∏–º–≤–æ–ª—ñ–≤)",
            "business_opportunities_pl": "Perspektywa LAZYSOFT dotyczƒÖca mo≈ºliwo≈õci automatyzacji (300-500 znak√≥w)",
            
            "lazysoft_recommendations_en": "LAZYSOFT automation recommendations (300-500 chars)",
            "lazysoft_recommendations_uk": "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó LAZYSOFT –∑ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü—ñ—ó (300-500 —Å–∏–º–≤–æ–ª—ñ–≤)",
            "lazysoft_recommendations_pl": "Rekomendacje LAZYSOFT dotyczƒÖce automatyzacji (300-500 znak√≥w)",
            
            "key_takeaways_en": ["specific fact from article", "specific tech mentioned", "specific number"],
            "key_takeaways_uk": ["–∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏–π —Ñ–∞–∫—Ç –∑—ñ —Å—Ç–∞—Ç—Ç—ñ", "–∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞ —Ç–µ—Ö–Ω–æ–ª–æ–≥—ñ—è", "–∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞ —Ü–∏—Ñ—Ä–∞"],
            "key_takeaways_pl": ["konkretny fakt z artyku≈Çu", "konkretna technologia", "konkretna liczba"],
            
            "interesting_facts_en": ["stat FROM article with source", "trend FROM article"],
            "interesting_facts_uk": ["—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ó–Ü —Å—Ç–∞—Ç—Ç—ñ –∑ –¥–∂–µ—Ä–µ–ª–æ–º", "—Ç—Ä–µ–Ω–¥ –ó–Ü —Å—Ç–∞—Ç—Ç—ñ"],
            "interesting_facts_pl": ["statystyka Z artyku≈Çu ze ≈∫r√≥d≈Çem", "trend Z artyku≈Çu"],
            
            "implementation_steps_en": ["step 1 based on article topic", "step 2", "step 3"],
            "implementation_steps_uk": ["–∫—Ä–æ–∫ 1 –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Ç–µ–º–∏ —Å—Ç–∞—Ç—Ç—ñ", "–∫—Ä–æ–∫ 2", "–∫—Ä–æ–∫ 3"],
            "implementation_steps_pl": ["krok 1 oparty na temacie artyku≈Çu", "krok 2", "krok 3"]
        }}
        """

        try:
            self.logger.info("[AI] –ì–µ–Ω–µ—Ä—É—î–º–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π 3-–º–æ–≤–Ω–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç ~2000 —Å–∏–º–≤–æ–ª—ñ–≤...")
            response = self._call_ai_model(main_prompt, max_tokens=5000)
            self.logger.info(f"[AI] –û—Ç—Ä–∏–º–∞–Ω–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å: {len(response)} —Å–∏–º–≤–æ–ª—ñ–≤")
            
            cleaned = self._clean_json_response(response)
            self.logger.info(f"[AI] –û—á–∏—â–µ–Ω–æ JSON: {len(cleaned)} —Å–∏–º–≤–æ–ª—ñ–≤")
            
            content_data = json.loads(cleaned)
            self.logger.info(f"[AI] –£—Å–ø—ñ—à–Ω–æ —Ä–æ–∑–ø–∞—Ä—Å–µ–Ω–æ JSON –∑ {len(content_data)} –ø–æ–ª—è–º–∏")
            
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∏ —É–Ω—ñ–∫–∞–ª—å–Ω—ñ —Ç–∞ –Ω–µ —ñ–¥–µ–Ω—Ç–∏—á–Ω—ñ –æ—Ä–∏–≥—ñ–Ω–∞–ª—É
            original_clean = original_title.strip().lower() if original_title else ""
            
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ AI –∑–≥–µ–Ω–µ—Ä—É–≤–∞–≤ —ñ–¥–µ–Ω—Ç–∏—á–Ω—ñ –¥–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª—É –∑–∞–≥–æ–ª–æ–≤–∫–∏
            title_issues = []
            if content_data.get("title_en", "").strip().lower() == original_clean:
                title_issues.append("title_en identical to original")
            if content_data.get("title_uk", "").strip().lower() == original_clean:
                title_issues.append("title_uk identical to original") 
            if content_data.get("title_pl", "").strip().lower() == original_clean:
                title_issues.append("title_pl identical to original")
            
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ –≤—Å—ñ –∑–∞–≥–æ–ª–æ–≤–∫–∏ —ñ–¥–µ–Ω—Ç–∏—á–Ω—ñ –º—ñ–∂ —Å–æ–±–æ—é
            if (content_data.get("title_en") == content_data.get("title_pl") or 
                content_data.get("title_en") == content_data.get("title_uk") or
                content_data.get("title_pl") == content_data.get("title_uk")):
                title_issues.append("titles identical between languages")
            
            if title_issues:
                self.logger.warning(f"[AI] –ü—Ä–æ–±–ª–µ–º–∏ –∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏: {', '.join(title_issues)}")
                self.logger.warning("[AI] –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ fallback –∑–∞–≥–æ–ª–æ–≤–∫–∏...")
                
                # –°—Ç–≤–æ—Ä—é—î–º–æ —É–Ω—ñ–∫–∞–ª—å–Ω—ñ fallback –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∑–∞–º—ñ—Å—Ç—å –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏—Ö
                source_name = raw_article.source.name if raw_article.source else "Tech Source"
                topic = self._extract_main_topic(original_title)
                
                content_data["title_en"] = f"LAZYSOFT analyzes: {topic} insights from {source_name}"
                content_data["title_uk"] = f"LAZYSOFT –∞–Ω–∞–ª—ñ–∑—É—î: —ñ–Ω—Å–∞–π—Ç–∏ –ø—Ä–æ {topic} –≤—ñ–¥ {source_name}"
                content_data["title_pl"] = f"LAZYSOFT analizuje: wglƒÖdy w {topic} od {source_name}"
            
        except json.JSONDecodeError as e:
            self.logger.error(
                f"‚ùå [AI JSON PARSE] –°—Ç–∞—Ç—Ç—è: {raw_article.title[:60]}...\n"
                f"   –ü–æ–º–∏–ª–∫–∞: {e}\n"
                f"   AI Response (–ø–µ—Ä—à—ñ 500 chars): {response[:500] if 'response' in locals() else 'N/A'}\n"
                f"   –ü—ñ—Å–ª—è –æ—á–∏—â–µ–Ω–Ω—è: {cleaned[:500] if 'cleaned' in locals() else 'N/A'}\n"
                f"   Content length: {len(content_for_ai)}"
            )
            content_data = self._create_fallback_content_dict(raw_article, category_info, content_to_use)
            
        except Exception as e:
            self.logger.error(
                f"‚ùå [AI CRITICAL] –°—Ç–∞—Ç—Ç—è: {raw_article.title[:60]}...\n"
                f"   –¢–∏–ø: {type(e).__name__}\n"
                f"   –î–µ—Ç–∞–ª—ñ: {e}\n"
                f"   Content –ø–µ—Ä–µ–¥–∞–Ω–æ: {len(content_for_ai) if 'content_for_ai' in locals() else 'N/A'} —Å–∏–º–≤–æ–ª—ñ–≤"
            )
            content_data = self._create_fallback_content_dict(raw_article, category_info, content_to_use)

        # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –¥–æ–≤–∂–∏–Ω summary
        content_data = self._normalize_lengths(content_data)

        # SEO / CTA / cost
        seo = self._generate_seo_metadata(content_data, category)
        cta_buttons = self._generate_cta_buttons(category)
        cost = self._calculate_cost(main_prompt, json.dumps(content_data))

        title_en = content_data.get("title_en", original_title)

        return {
            "title_en": title_en,
            "title_pl": content_data.get("title_pl", original_title),
            "title_uk": content_data.get("title_uk", original_title),

            # —Ç—É—Ç —Ç–µ–ø–µ—Ä –ª–µ–∂–∏—Ç—å –Ω–∞—à –û–†–ò–ì–Ü–ù–ê–õ–¨–ù–ò–ô 2000‚Äì3000 —Å–∏–º–≤. —Ç–µ–∫—Å—Ç
            "summary_en": content_data.get("summary_en", content_for_ai[:2500]),
            "summary_pl": content_data.get("summary_pl", content_for_ai[:2500]),
            "summary_uk": content_data.get("summary_uk", content_for_ai[:2500]),

            "business_insight_en": content_data.get("business_insight_en", ""),
            "business_insight_pl": content_data.get("business_insight_pl", ""),
            "business_insight_uk": content_data.get("business_insight_uk", ""),

            "business_opportunities_en": content_data.get("business_opportunities_en", ""),
            "business_opportunities_pl": content_data.get("business_opportunities_pl", ""),
            "business_opportunities_uk": content_data.get("business_opportunities_uk", ""),

            "lazysoft_recommendations_en": content_data.get("lazysoft_recommendations_en", ""),
            "lazysoft_recommendations_pl": content_data.get("lazysoft_recommendations_pl", ""),
            "lazysoft_recommendations_uk": content_data.get("lazysoft_recommendations_uk", ""),

            # –ù–æ–≤—ñ –ø–æ–ª—è –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É
            "key_takeaways_en": content_data.get("key_takeaways_en", []),
            "key_takeaways_pl": content_data.get("key_takeaways_pl", []),
            "key_takeaways_uk": content_data.get("key_takeaways_uk", []),
            "interesting_facts_en": content_data.get("interesting_facts_en", []),
            "interesting_facts_pl": content_data.get("interesting_facts_pl", []),
            "interesting_facts_uk": content_data.get("interesting_facts_uk", []),

            "implementation_steps_en": content_data.get("implementation_steps_en", []),
            "implementation_steps_pl": content_data.get("implementation_steps_pl", []),
            "implementation_steps_uk": content_data.get("implementation_steps_uk", []),

            "category_slug": category,
            "priority": category_info.get("priority", 2),

            "ai_model_used": self.preferred_model,
            "processing_time": 0,
            "cost": cost,
            **seo,
            "cta_buttons": cta_buttons
        }


    def _create_fallback_content_dict(self, raw_article: RawArticle, category_info: Dict, content_to_use: str = None) -> dict:
        """Fallback –∫–æ–Ω—Ç–µ–Ω—Ç - –ê–ù–ê–õ–Ü–¢–ò–ß–ù–ò–ô, –Ω–µ –∫–æ–ø—ñ—é—î –æ—Ä–∏–≥—ñ–Ω–∞–ª"""
        
        # –í–ê–ñ–õ–ò–í–û: –ª–æ–≥—É—î–º–æ —â–æ fallback —Å–ø—Ä–∞—Ü—é–≤–∞–≤
        self.logger.warning(
            f"‚ö†Ô∏è [FALLBACK] AI –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π! –°—Ç–∞—Ç—Ç—è: '{raw_article.title[:80]}...'\n"
            f"   –ö–∞—Ç–µ–≥–æ—Ä—ñ—è: {category_info.get('category', 'unknown')}\n"
            f"   Source: {raw_article.source.name if raw_article.source else 'N/A'}\n"
            f"   Content length: {len(content_to_use or raw_article.content or '')} —Å–∏–º–≤–æ–ª—ñ–≤\n"
            f"   ‚ö†Ô∏è –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ fallback - –∫–æ–Ω—Ç–µ–Ω—Ç –±—É–¥–µ –±–∞–∑–æ–≤–∏–º!"
        )
        
        original_title = raw_article.title or "Tech Update"
        source_name = raw_article.source.name if raw_article.source else "tech source"
        category = category_info.get('category', 'technology')
        
        # –ë–µ—Ä–µ–º–æ –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –±–∞–∑–æ–≤–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É
        if content_to_use:
            full_content = content_to_use
        else:
            full_content = raw_article.content or raw_article.summary or ""
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ –ê–ù–ê–õ–Ü–¢–ò–ß–ù–ò–ô –∑–∞–≥–æ–ª–æ–≤–æ–∫, –ù–ï –∫–æ–ø—ñ—é –æ—Ä–∏–≥—ñ–Ω–∞–ª—É
        analytical_title_en = f"Latest {category} developments: {source_name} reports on {original_title[:50]}"
        analytical_title_uk = f"–û—Å—Ç–∞–Ω–Ω—ñ –Ω–æ–≤–∏–Ω–∏ {category}: {source_name} –ø–æ–≤—ñ–¥–æ–º–ª—è—î –ø—Ä–æ {original_title[:50]}"
        analytical_title_pl = f"Najnowsze wiadomo≈õci {category}: {source_name} informuje o {original_title[:50]}"
        
        # Fallback summary - –±–∞–∑–æ–≤–∏–π –∞–Ω–∞–ª—ñ–∑
        summary_intro_en = f"According to {source_name}, recent developments in {category} sector indicate "
        summary_intro_uk = f"–ó–∞ –¥–∞–Ω–∏–º–∏ {source_name}, –æ—Å—Ç–∞–Ω–Ω—ñ —Ä–æ–∑—Ä–æ–±–∫–∏ –≤ —Å–µ–∫—Ç–æ—Ä—ñ {category} –≤–∫–∞–∑—É—é—Ç—å –Ω–∞ "
        summary_intro_pl = f"Wed≈Çug {source_name}, najnowsze rozw√≥j w sektorze {category} wskazuje na "
        
        # –î–æ–¥–∞—î–º–æ —á–∞—Å—Ç–∏–Ω—É –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç—É —è–∫ context, –∞–ª–µ –∑ –≤–≤–µ–¥–µ–Ω–Ω—è–º
        content_snippet = full_content[:1500] if full_content else "technological advancement in the industry"
        
        # –í–∏—Ç—è–≥—É—î–º–æ –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞ –∑—ñ —Å—Ç–∞—Ç—Ç—ñ –¥–ª—è key_takeaways
        title_words = [w for w in original_title.split() if len(w) > 4]
        
        return {
            # –ê–ù–ê–õ–Ü–¢–ò–ß–ù–Ü –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∑ –¥–∂–µ—Ä–µ–ª–æ–º
            "title_en": analytical_title_en, 
            "title_pl": analytical_title_pl, 
            "title_uk": analytical_title_uk,
            
            # –ë–∞–∑–æ–≤–∏–π –∞–Ω–∞–ª—ñ–∑ –∑ –≤–≤–µ–¥–µ–Ω–Ω—è–º –¥–∂–µ—Ä–µ–ª–∞
            "summary_en": f"{summary_intro_en}significant changes in business technology landscape. {content_snippet} For European SMBs, these developments may present opportunities for process automation and efficiency improvements. Detailed AI analysis temporarily unavailable - refer to original source for complete information.",
            
            "summary_pl": f"{summary_intro_pl}istotne zmiany w krajobrazie technologii biznesowej. {content_snippet} Dla europejskich M≈öP rozw√≥j ten mo≈ºe stanowiƒá okazjƒô do automatyzacji proces√≥w i poprawy efektywno≈õci. Szczeg√≥≈Çowa analiza AI tymczasowo niedostƒôpna.",
            
            "summary_uk": f"{summary_intro_uk}–∑–Ω–∞—á–Ω—ñ –∑–º—ñ–Ω–∏ –≤ –ª–∞–Ω–¥—à–∞—Ñ—Ç—ñ –±—ñ–∑–Ω–µ—Å-—Ç–µ—Ö–Ω–æ–ª–æ–≥—ñ–π. {content_snippet} –î–ª—è —î–≤—Ä–æ–ø–µ–π—Å—å–∫–∏—Ö –ú–°–ü —Ü—ñ —Ä–æ–∑—Ä–æ–±–∫–∏ –º–æ–∂—É—Ç—å –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—Ç–∏ –º–æ–∂–ª–∏–≤–æ—Å—Ç—ñ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü—ñ—ó –ø—Ä–æ—Ü–µ—Å—ñ–≤ —Ç–∞ –ø—ñ–¥–≤–∏—â–µ–Ω–Ω—è –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ. –î–µ—Ç–∞–ª—å–Ω–∏–π AI –∞–Ω–∞–ª—ñ–∑ —Ç–∏–º—á–∞—Å–æ–≤–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π.",

            # Insights –∑ –∞–Ω–∞–ª—ñ—Ç–∏—á–Ω–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
            "business_insight_en": f"Based on {source_name} report about {category}, European SMBs should monitor these technological developments for potential automation and optimization opportunities. Full analysis requires detailed review.",
            
            "business_insight_pl": f"Na podstawie raportu {source_name} dotyczƒÖcego {category}, europejskie M≈öP powinny monitorowaƒá te rozw√≥j technologiczne pod kƒÖtem potencjalnych mo≈ºliwo≈õci automatyzacji. Pe≈Çna analiza wymaga szczeg√≥≈Çowego przeglƒÖdu.",
            
            "business_insight_uk": f"–ù–∞ –æ—Å–Ω–æ–≤—ñ –∑–≤—ñ—Ç—É {source_name} –ø—Ä–æ {category}, —î–≤—Ä–æ–ø–µ–π—Å—å–∫—ñ –ú–°–ü –º–∞—é—Ç—å –≤—ñ–¥—Å—Ç–µ–∂—É–≤–∞—Ç–∏ —Ü—ñ —Ç–µ—Ö–Ω–æ–ª–æ–≥—ñ—á–Ω—ñ —Ä–æ–∑—Ä–æ–±–∫–∏ –¥–ª—è –ø–æ—Ç–µ–Ω—Ü—ñ–π–Ω–∏—Ö –º–æ–∂–ª–∏–≤–æ—Å—Ç–µ–π –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü—ñ—ó. –ü–æ–≤–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –ø–æ—Ç—Ä–µ–±—É—î –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ–≥–ª—è–¥—É.",
            
            # Opportunities - –Ω–µ generic!
            "business_opportunities_en": f"Technology developments reported by {source_name} may offer process automation potential. LAZYSOFT recommends detailed assessment for specific business applications.",
            
            "business_opportunities_pl": f"Rozw√≥j technologiczny zg≈Çoszony przez {source_name} mo≈ºe oferowaƒá potencja≈Ç automatyzacji proces√≥w. LAZYSOFT zaleca szczeg√≥≈ÇowƒÖ ocenƒô dla konkretnych zastosowa≈Ñ biznesowych.",
            
            "business_opportunities_uk": f"–¢–µ—Ö–Ω–æ–ª–æ–≥—ñ—á–Ω—ñ —Ä–æ–∑—Ä–æ–±–∫–∏ –≤—ñ–¥ {source_name} –º–æ–∂—É—Ç—å –∑–∞–ø—Ä–æ–ø–æ–Ω—É–≤–∞—Ç–∏ –ø–æ—Ç–µ–Ω—Ü—ñ–∞–ª –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü—ñ—ó. LAZYSOFT —Ä–µ–∫–æ–º–µ–Ω–¥—É—î –¥–µ—Ç–∞–ª—å–Ω—É –æ—Ü—ñ–Ω–∫—É –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏—Ö –±—ñ–∑–Ω–µ—Å-–∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω—å.",
            
            # LAZYSOFT recommendations
            "lazysoft_recommendations_en": f"Contact LAZYSOFT for professional analysis of how {category} developments from {source_name} can be applied to your business automation strategy.",
            
            "lazysoft_recommendations_pl": f"Skontaktuj siƒô z LAZYSOFT w celu profesjonalnej analizy, jak rozw√≥j {category} od {source_name} mo≈ºe byƒá zastosowany do Twojej strategii automatyzacji biznesowej.",
            
            "lazysoft_recommendations_uk": f"–ó–≤'—è–∂—ñ—Ç—å—Å—è –∑ LAZYSOFT –¥–ª—è –ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É —Ç–æ–≥–æ, —è–∫ —Ä–æ–∑—Ä–æ–±–∫–∏ {category} –≤—ñ–¥ {source_name} –º–æ–∂—É—Ç—å –±—É—Ç–∏ –∑–∞—Å—Ç–æ—Å–æ–≤–∞–Ω—ñ –¥–æ –≤–∞—à–æ—ó —Å—Ç—Ä–∞—Ç–µ–≥—ñ—ó –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü—ñ—ó –±—ñ–∑–Ω–µ—Å—É.",
            
            # –ù–æ–≤—ñ –ø–æ–ª—è –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É
            "key_takeaways_en": [
                f"Article discusses {title_words[0] if title_words else 'technology'}",
                f"Source: {source_name}",
                f"Category: {category}"
            ],
            "key_takeaways_uk": [
                f"–°—Ç–∞—Ç—Ç—è –æ–±–≥–æ–≤–æ—Ä—é—î {title_words[0] if title_words else '—Ç–µ—Ö–Ω–æ–ª–æ–≥—ñ—é'}",
                f"–î–∂–µ—Ä–µ–ª–æ: {source_name}",
                f"–ö–∞—Ç–µ–≥–æ—Ä—ñ—è: {category}"
            ],
            "key_takeaways_pl": [
                f"Artyku≈Ç omawia {title_words[0] if title_words else 'technologiƒô'}",
                f"≈πr√≥d≈Ço: {source_name}",
                f"Kategoria: {category}"
            ],
            "interesting_facts_en": [f"Technology development reported by {source_name}", f"Potential impact on {category} sector", "Automation opportunities identified"],
            "interesting_facts_pl": [f"Rozw√≥j technologiczny zg≈Çoszony przez {source_name}", f"Potencjalny wp≈Çyw na sektor {category}", "Zidentyfikowane mo≈ºliwo≈õci automatyzacji"],
            "interesting_facts_uk": [f"–¢–µ—Ö–Ω–æ–ª–æ–≥—ñ—á–Ω–∏–π —Ä–æ–∑–≤–∏—Ç–æ–∫ –≤—ñ–¥ {source_name}", f"–ü–æ—Ç–µ–Ω—Ü—ñ–π–Ω–∏–π –≤–ø–ª–∏–≤ –Ω–∞ —Å–µ–∫—Ç–æ—Ä {category}", "–í–∏—è–≤–ª–µ–Ω—ñ –º–æ–∂–ª–∏–≤–æ—Å—Ç—ñ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü—ñ—ó"],
            
            "implementation_steps_en": ["Assess current business processes", "Identify automation opportunities", "Plan technology integration", "Execute and monitor results"],
            "implementation_steps_pl": ["Oce≈Ñ obecne procesy biznesowe", "Zidentyfikuj mo≈ºliwo≈õci automatyzacji", "Zaplanuj integracjƒô technologii", "Wykonaj i monitoruj wyniki"],
            "implementation_steps_uk": ["–û—Ü—ñ–Ω—ñ—Ç—å –ø–æ—Ç–æ—á–Ω—ñ –±—ñ–∑–Ω–µ—Å-–ø—Ä–æ—Ü–µ—Å–∏", "–í–∏–∑–Ω–∞—á—Ç–µ –º–æ–∂–ª–∏–≤–æ—Å—Ç—ñ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü—ñ—ó", "–°–ø–ª–∞–Ω—É–π—Ç–µ —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—é —Ç–µ—Ö–Ω–æ–ª–æ–≥—ñ–π", "–í–∏–∫–æ–Ω–∞–π—Ç–µ —Ç–∞ –≤—ñ–¥—Å—Ç–µ–∂—É–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏"],
        }

    def generate_full_content(self, content: str, language: str) -> str:
        """–ì–µ–Ω–µ—Ä—É—î –ø–æ–≤–Ω–∏–π Business Impact –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ñ–π –º–æ–≤—ñ (2000-3000 —Å–∏–º–≤–æ–ª—ñ–≤)"""
        try:
            # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ AI –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ Business Impact –∫–æ–Ω—Ç–µ–Ω—Ç—É
            prompt = f"""
–Ø–∫ –µ–∫—Å–ø–µ—Ä—Ç LAZYSOFT –∑ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü—ñ—ó –±—ñ–∑–Ω–µ—Å-–ø—Ä–æ—Ü–µ—Å—ñ–≤, —Å—Ç–≤–æ—Ä–∏ –¥–µ—Ç–∞–ª—å–Ω–∏–π Business Impact –∞–Ω–∞–ª—ñ–∑ –Ω–∞ {language} –º–æ–≤—ñ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –Ω–∞—Å—Ç—É–ø–Ω–æ—ó —Å—Ç–∞—Ç—Ç—ñ:

{content}

–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∞–Ω–∞–ª—ñ–∑—É:
1. –ö–ª—é—á–æ–≤—ñ —Ç–µ—Ö–Ω–æ–ª–æ–≥—ñ—á–Ω—ñ —Ç—Ä–µ–Ω–¥–∏ —Ç–∞ —ó—Ö –≤–ø–ª–∏–≤ –Ω–∞ –±—ñ–∑–Ω–µ—Å
2. –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ñ –º–æ–∂–ª–∏–≤–æ—Å—Ç—ñ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü—ñ—ó —Ç–∞ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó
3. –ü—Ä–∞–∫—Ç–∏—á–Ω—ñ –∫—Ä–æ–∫–∏ –≤–ø—Ä–æ–≤–∞–¥–∂–µ–Ω–Ω—è –¥–ª—è –ú–°–ë
4. ROI –æ—Ü—ñ–Ω–∫–∞ —Ç–∞ –ø–æ—Ç–µ–Ω—Ü—ñ–π–Ω—ñ –µ–∫–æ–Ω–æ–º—ñ—ó
5. –†–∏–∑–∏–∫–∏ —Ç–∞ —Å–ø–æ—Å–æ–±–∏ —ó—Ö –º—ñ–Ω—ñ–º—ñ–∑–∞—Ü—ñ—ó
6. –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ñ –ø–µ—Ä–µ–≤–∞–≥–∏ —Ç–∞ –º–æ–∂–ª–∏–≤–æ—Å—Ç—ñ —Ä–æ—Å—Ç—É

–í–∏–º–æ–≥–∏:
- –î–æ–≤–∂–∏–Ω–∞: 2000-3000 —Å–∏–º–≤–æ–ª—ñ–≤
- –ü—Ä–∞–∫—Ç–∏—á–Ω–∏–π —Ñ–æ–∫—É—Å –Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü—ñ—ó
- –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ñ —Ü–∏—Ñ—Ä–∏ —Ç–∞ –ø—Ä–∏–∫–ª–∞–¥–∏
- –ê–¥–∞–ø—Ç–æ–≤–∞–Ω–æ –¥–ª—è {language} —Ä–∏–Ω–∫—É
- –°—Ç–∏–ª—å LAZYSOFT: –µ–∫—Å–ø–µ—Ä—Ç–Ω–∏–π, –∞–ª–µ –∑—Ä–æ–∑—É–º—ñ–ª–∏–π
- –ù–ï –∫–æ–ø—ñ—é–π –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π —Ç–µ–∫—Å—Ç - —Å—Ç–≤–æ—Ä—é–π –û–†–ò–ì–Ü–ù–ê–õ–¨–ù–ò–ô –∞–Ω–∞–ª—ñ–∑
"""
            
            full_content = self._call_ai_model(prompt, max_tokens=3000)
            return full_content.strip()
            
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó Business Impact –¥–ª—è {language}: {e}")
            # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç —è–∫—â–æ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—è –Ω–µ –≤–¥–∞–ª–∞—Å—è
            return content