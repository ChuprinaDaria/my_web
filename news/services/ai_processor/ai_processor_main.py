import time
from typing import Dict, Optional
from django.utils import timezone
from django.db.models import Sum, Q, F
from datetime import datetime, timedelta

from .ai_processor_content import AIContentProcessor
from .ai_processor_helpers import AIProcessorHelpers
from .ai_processor_database import AIProcessorDatabase
from news.models import RawArticle, ProcessedArticle, AIProcessingLog 

class AINewsProcessor(AIContentProcessor, AIProcessorHelpers, AIProcessorDatabase):
    """–ì–æ–ª–æ–≤–Ω–∏–π AI –ø—Ä–æ—Ü–µ—Å–æ—Ä –¥–ª—è –Ω–æ–≤–∏–Ω - –æ—Å–Ω–æ–≤–Ω–∞ –æ–±—Ä–æ–±–∫–∞"""

    def process_article(self, raw_article: RawArticle, full_content: str = None) -> Optional[ProcessedArticle]:
        """–û–±—Ä–æ–±–ª—è—î –æ–¥–Ω—É —Å–∏—Ä—É —Å—Ç–∞—Ç—Ç—é —á–µ—Ä–µ–∑ AI –∑ FiveFilters –∑–±–∞–≥–∞—á–µ–Ω–Ω—è–º"""
        start_time = time.time()
        self.logger.info(f"[AI] –û–±—Ä–æ–±–∫–∞ —Å—Ç–∞—Ç—Ç—ñ: {raw_article.title[:50]}...")

        try:
            # 0) –ù–û–í–ò–ô –ö–†–û–ö: –ó–±–∞–≥–∞—á–µ–Ω–Ω—è FiveFilters –ü–ï–†–ï–î AI –æ–±—Ä–æ–±–∫–æ—é
            enhanced_content = self._enhance_with_fivefilters(raw_article)
            
            # 1) –ê–Ω–∞–ª—ñ–∑ + –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü—ñ—è (—Ç–µ–ø–µ—Ä –Ω–∞ –∑–±–∞–≥–∞—á–µ–Ω–æ–º—É –∫–æ–Ω—Ç–µ–Ω—Ç—ñ)
            category_info = self._categorize_article(raw_article)
            self.logger.info(f"[AI] –ö–∞—Ç–µ–≥–æ—Ä—ñ—è –≤–∏–∑–Ω–∞—á–µ–Ω–∞: {category_info['category']}")

            # 2) –¢—Ä–∏–º–æ–≤–Ω–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç (–≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –∑–±–∞–≥–∞—á–µ–Ω–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç –∞–±–æ –ø–µ—Ä–µ–¥–∞–Ω–∏–π full_content)
            processed_content = self._create_multilingual_content(raw_article, category_info, full_content)
            self.logger.info("[AI] –¢—Ä–∏–º–æ–≤–Ω–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç —Å—Ç–≤–æ—Ä–µ–Ω–æ ‚úÖ")

            # 3) –°—Ç–æ–∫–æ–≤—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑–∞–º—ñ—Å—Ç—å AI –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó (—è–∫ —Ç–∏ —Ö–æ—Ç—ñ–ª–∞)
            from news.services.stock_image_service import stock_image_service

            self.logger.info("[IMAGE] –ü–æ—à—É–∫ —Å—Ç–æ–∫–æ–≤–æ–≥–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è...")

            # –í–∏—Ç—è–≥—É—î–º–æ –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞ –∑ –∫–æ–Ω—Ç–µ–Ω—Ç—É
            content_keywords = self._extract_keywords_from_content(
                raw_article.content or raw_article.summary or ""
            )

            try:
                image_url = stock_image_service.get_image_for_article(
                    title=raw_article.title,
                    category=category_info.get('category_slug', 'general'),
                    keywords=content_keywords
                )
                
                processed_content["ai_image_url"] = image_url
                
                if image_url:
                    self.logger.info(f"[IMAGE] –°—Ç–æ–∫–æ–≤–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑–Ω–∞–π–¥–µ–Ω–æ: {image_url}")
                else:
                    self.logger.warning("[IMAGE] –°—Ç–æ–∫–æ–≤–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")
                    
            except Exception as img_err:
                self.logger.error(f"[IMAGE] –ü–æ–º–∏–ª–∫–∞ –ø–æ—à—É–∫—É —Å—Ç–æ–∫–æ–≤–æ–≥–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è: {img_err}")
                processed_content["ai_image_url"] = None

            # 4) –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –æ–±—Ä–æ–±–ª–µ–Ω—É —Å—Ç–∞—Ç—Ç—é (—Ä–µ—à—Ç–∞ –∫–æ–¥—É –∑–∞–ª–∏—à–∞—î—Ç—å—Å—è)
            processed_article = self._save_processed_article(raw_article, processed_content)

            # 4.1) –ó–∞–ø–∏—Å—É—î–º–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
            image_url_to_save = processed_content.get("ai_image_url")
            self.logger.info(f"[IMAGE] –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è: {image_url_to_save}")
            if image_url_to_save:
                processed_article.ai_image_url = image_url_to_save
                processed_article.save(update_fields=["ai_image_url"])
                self.logger.info(f"[IMAGE] ‚úÖ –ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {processed_article.ai_image_url}")
            else:
                self.logger.warning("[IMAGE] ‚ö†Ô∏è –ù–µ–º–∞—î URL –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è")

            self.logger.info("[AI] –°—Ç–∞—Ç—Ç—é –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ –±–∞–∑—É ‚úÖ")

            # 4.2) –ì–µ–Ω–µ—Ä—É—î–º–æ –ø–æ–≤–Ω–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è —Ç–æ–ø-—Å—Ç–∞—Ç–µ–π (—è–∫—â–æ –ø–µ—Ä–µ–¥–∞–Ω–æ full_content)
            if full_content and len(full_content) > 1000:  # –¢—ñ–ª—å–∫–∏ –¥–ª—è —Å—Ç–∞—Ç–µ–π –∑ –¥–æ—Å—Ç–∞—Ç–Ω—ñ–º –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º
                self.logger.info("üìù –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –ø–æ–≤–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç—É –¥–ª—è —Ç–æ–ø-—Å—Ç–∞—Ç—Ç—ñ...")
                try:
                    processed_article.full_content_en = self.generate_full_content(full_content, 'en')
                    processed_article.full_content_pl = self.generate_full_content(full_content, 'pl')
                    processed_article.full_content_uk = self.generate_full_content(full_content, 'uk')
                    processed_article.full_content_parsed = True
                    processed_article.original_word_count = len(full_content.split())
                    processed_article.reading_time = max(5, processed_article.original_word_count // 200)
                    processed_article.save()
                    self.logger.info("‚úÖ –ü–æ–≤–Ω–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ —Ç–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–æ")
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –ø–æ–≤–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç—É: {e}")

            # 5) –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            processing_time = time.time() - start_time
            processed_content["processing_time"] = processing_time
            self._log_ai_processing(raw_article, "full_processing", processed_content)

            # –ü–æ–∑–Ω–∞—á–∞—î–º–æ —è–∫ –æ–±—Ä–æ–±–ª–µ–Ω–∏–π
            raw_article.is_processed = True
            raw_article.save(update_fields=["is_processed"])

            self.stats["processed"] += 1
            self.stats["successful"] += 1
            self.stats["total_time"] += processing_time
            self.stats["total_cost"] += processed_content.get("cost", 0.0)

            self.logger.info(
                "[SUCCESS] –°—Ç–∞—Ç—Ç—é –æ–±—Ä–æ–±–ª–µ–Ω–æ –∑–∞ %.2fs, –≤–∞—Ä—Ç—ñ—Å—Ç—å: $%.4f",
                processing_time,
                processed_content.get("cost", 0.0),
            )

            return processed_article

        except Exception as e:
            self.stats["failed"] += 1
            error_msg = str(e)

            raw_article.processing_attempts = (raw_article.processing_attempts or 0) + 1
            raw_article.error_message = error_msg
            raw_article.save(update_fields=["processing_attempts", "error_message"])

            self._log_ai_processing(raw_article, "error", {"error": error_msg})
            self.logger.error(f"[ERROR] –ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ —Å—Ç–∞—Ç—Ç—ñ: {error_msg}")
            return None

    

    def process_top5_by_engagement(self, days: int = 7) -> Dict:
        """–û–±—Ä–æ–±–ª—è—î —Ç–æ–ø-5 —Å—Ç–∞—Ç–µ–π –ø–æ engagement –∑–∞ –æ—Å—Ç–∞–Ω–Ω—ñ –¥–Ω—ñ"""
        
        cutoff = timezone.now() - timedelta(days=days)

        # 1) —Ç–æ–ø –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó –∑–∞ –ø–µ—Ä–µ–≥–ª—è–¥–∞–º–∏
        top_cats = (ProcessedArticle.objects
            .filter(published_at__gte=cutoff, status='published')
            .values('category__slug')
            .annotate(total_views=Sum(F('views_count_uk') + F('views_count_en') + F('views_count_pl')))
            .order_by('-total_views')[:3])

        cat_slugs = [c['category__slug'] for c in top_cats] or ['general']

        # 2) —Å–≤—ñ–∂—ñ RawArticle –∑ —Ü–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä—ñ–π (–Ω–µ –æ–±—Ä–æ–±–ª–µ–Ω—ñ)
        queryset = (RawArticle.objects
            .filter(is_processed=False, is_duplicate=False, source__category__in=cat_slugs)
            .order_by('-published_at')[:5])

        results = []
        for article in queryset:
            result = self.process_article(article)
            results.append(result)
            time.sleep(1)

        success = len([r for r in results if r])
        return {
            'processed': len(results),
            'successful': success,
            'failed': len(results) - success
        }

    def _log_ai_processing(self, raw_article: RawArticle, log_type: str, data):
        """–õ–æ–≥—É—î AI –æ–±—Ä–æ–±–∫—É"""
        try:
            # –ë–ï–ó–ü–ï–ß–ù–ï –û–¢–†–ò–ú–ê–ù–ù–Ø –ó–ù–ê–ß–ï–ù–¨
            if isinstance(data, dict):
                ai_model = data.get('ai_model_used', self.preferred_model)
                processing_time = data.get('processing_time', 0)
                cost = data.get('cost', 0)
                error_msg = data.get('error', '')
                success = 'error' not in data
            else:
                # –Ø–∫—â–æ data —Ü–µ ProcessedContent –∞–±–æ —ñ–Ω—à–∏–π –æ–±'—î–∫—Ç
                ai_model = getattr(data, 'ai_model_used', self.preferred_model)
                processing_time = getattr(data, 'processing_time', 0)
                cost = getattr(data, 'cost', 0)
                error_msg = ''
                success = True
            
            AIProcessingLog.objects.create(
                article=raw_article,
                log_type=log_type,
                model_used=ai_model,
                processing_time=processing_time,
                cost=cost,
                success=success,
                input_data={'title': raw_article.title[:100]},
                output_data={'status': 'processed' if success else 'error'},
                error_message=error_msg
            )
        except Exception as e:
            self.logger.error(f"[ERROR] –ü–æ–º–∏–ª–∫–∞ –ª–æ–≥—É–≤–∞–Ω–Ω—è: {e}")


    def _enhance_with_fivefilters(self, raw_article: RawArticle) -> str:
        """–ó–±–∞–≥–∞—á—É—î —Å—Ç–∞—Ç—Ç—é –ø–æ–≤–Ω–∏–º —Ç–µ–∫—Å—Ç–æ–º —á–µ—Ä–µ–∑ FiveFilters"""
        
        # –î–û –∑–±–∞–≥–∞—á–µ–Ω–Ω—è
        original_length = len(raw_article.content or "")
        self.logger.info(f"[FIVEFILTERS] –î–û: {original_length} —Å–∏–º–≤–æ–ª—ñ–≤")
        
        # –Ø–∫—â–æ –∫–æ–Ω—Ç–µ–Ω—Ç –≤–∂–µ –¥–æ–≤–≥–∏–π - –º–æ–∂–ª–∏–≤–æ –≤–∂–µ –∑–±–∞–≥–∞—á–µ–Ω–æ
        if original_length > 1500:
            self.logger.info(f"[FIVEFILTERS] –ö–æ–Ω—Ç–µ–Ω—Ç –≤–∂–µ –¥–æ–≤–≥–∏–π ({original_length} —Å–∏–º–≤), –≤–≤–∞–∂–∞—î–º–æ –ø–æ–≤–Ω–∏–º")
            # –í—Å—Ç–∞–Ω–æ–≤–ª—é—î–º–æ —Ñ–ª–∞–≥ –ø–æ–≤–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç—É
            raw_article.has_full_content = True
            raw_article.save(update_fields=['has_full_content'])
            return raw_article.content or ""
        
        try:
            from news.services.fulltext_extractor import FullTextExtractor
            
            self.logger.info(f"[FIVEFILTERS] –ó–±–∞–≥–∞—á–µ–Ω–Ω—è: {raw_article.original_url}")
            
            extractor = FullTextExtractor()
            full_content = extractor.extract_article(raw_article.original_url)
            
            # –ü–Ü–°–õ–Ø –∑–±–∞–≥–∞—á–µ–Ω–Ω—è
            if full_content and len(full_content) > original_length:
                improvement = len(full_content) - original_length
                
                # –ó–ë–ï–†–Ü–ì–ê–Ñ–ú–û –∑–±–∞–≥–∞—á–µ–Ω–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç –≤ –ë–î
                raw_article.content = full_content
                raw_article.has_full_content = True
                raw_article.save(update_fields=['content', 'has_full_content'])
                
                self.logger.info(
                    f"[FIVEFILTERS] ‚úÖ –ü–Ü–°–õ–Ø: {len(full_content)} —Å–∏–º–≤–æ–ª—ñ–≤ (+{improvement})"
                )
                return full_content
            else:
                self.logger.warning(f"[FIVEFILTERS] ‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–±–∞–≥–∞—Ç–∏—Ç–∏ –∞–±–æ –∫–æ–Ω—Ç–µ–Ω—Ç –∫–æ—Ä–æ—Ç—à–∏–π")
                raw_article.has_full_content = False
                raw_article.save(update_fields=['has_full_content'])
                return raw_article.content or raw_article.summary or ""
                
        except Exception as e:
            self.logger.warning(f"[FIVEFILTERS] ‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")
            raw_article.has_full_content = False
            raw_article.save(update_fields=['has_full_content'])
            return raw_article.content or raw_article.summary or ""


    def _extract_keywords_from_content(self, content: str) -> list:
        """–í–∏—Ç—è–≥—É—î –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞ –∑ –∫–æ–Ω—Ç–µ–Ω—Ç—É –¥–ª—è –ø–æ—à—É–∫—É –∑–æ–±—Ä–∞–∂–µ–Ω—å"""
        import re
        
        if not content:
            return []
        
        # –°—Ç–æ–ø-—Å–ª–æ–≤–∞
        stop_words = {
            'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 
            'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'being',
            'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could'
        }
        
        # –í–∏—Ç—è–≥—É—î–º–æ —Å–ª–æ–≤–∞
        words = re.findall(r'\b[a-zA-Z]{4,}\b', content.lower())
        
        # –†–∞—Ö—É—î–º–æ —á–∞—Å—Ç–æ—Ç—É
        word_freq = {}
        for word in words:
            if word not in stop_words:
                word_freq[word] = word_freq.get(word, 0) + 1
        
        # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ —Ç–æ–ø-5 –Ω–∞–π—á–∞—Å—Ç—ñ—à–∏—Ö
        keywords = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)
        return [word for word, freq in keywords[:5]]

    def _auto_prioritize_articles(self, articles: list) -> None:
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –≤—Å—Ç–∞–Ω–æ–≤–ª—é—î –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç–∏ —Ç–∞ —Ç–æ–ø-—Å—Ç–∞—Ç—Ç—ñ –Ω–∞ –æ—Å–Ω–æ–≤—ñ AI –∞–Ω–∞–ª—ñ–∑—É"""
        from django.utils import timezone
        from datetime import date
        
        if not articles:
            return
            
        self.logger.info(f"[PRIORITY] –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∞ –ø—Ä—ñ–æ—Ä–∏—Ç–∏–∑–∞—Ü—ñ—è {len(articles)} —Å—Ç–∞—Ç–µ–π...")
        
        # –°–æ—Ä—Ç—É—î–º–æ —Å—Ç–∞—Ç—Ç—ñ –∑–∞ –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç–æ–º —Ç–∞ —è–∫—ñ—Å—Ç—é –∫–æ–Ω—Ç–µ–Ω—Ç—É
        scored_articles = []
        
        for article in articles:
            score = self._calculate_article_score(article)
            scored_articles.append((article, score))
            
        # –°–æ—Ä—Ç—É—î–º–æ –∑–∞ —Å–∫–æ—Ä–æ–º (–Ω–∞–π–≤–∏—â–∏–π —Å–ø–æ—á–∞—Ç–∫—É)
        scored_articles.sort(key=lambda x: x[1], reverse=True)
        
        today = timezone.now().date()
        
        # –¢–æ–ø-5 —Å—Ç–∞—Ç–µ–π –æ—Ç—Ä–∏–º—É—é—Ç—å —Å–ø–µ—Ü—ñ–∞–ª—å–Ω–∏–π —Å—Ç–∞—Ç—É—Å
        top_count = min(5, len(scored_articles))
        
        for i, (article, score) in enumerate(scored_articles[:top_count]):
            # –í—Å—Ç–∞–Ω–æ–≤–ª—é—î–º–æ –≤–∏—Å–æ–∫–∏–π –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç –¥–ª—è —Ç–æ–ø-—Å—Ç–∞—Ç–µ–π
            priority = max(3, min(5, int(score // 20)))  # –°–∫–æ—Ä 0-100 -> –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç 3-5
            
            article.is_top_article = True
            article.article_rank = i + 1
            article.top_selection_date = today
            article.priority = priority
            
            article.save(update_fields=[
                'is_top_article', 'article_rank', 'top_selection_date', 'priority'
            ])
            
            self.logger.info(f"[TOP-{i+1}] {article.title_uk[:50]}... (—Å–∫–æ—Ä: {score:.1f}, –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç: {priority})")
        
        # –†–µ—à—Ç–∞ —Å—Ç–∞—Ç–µ–π –æ—Ç—Ä–∏–º—É—é—Ç—å –∑–≤–∏—á–∞–π–Ω–∏–π –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç
        for article, score in scored_articles[top_count:]:
            priority = max(2, min(4, int(score // 25)))  # –ù–∏–∂—á–∏–π –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç
            
            if article.priority != priority:
                article.priority = priority
                article.save(update_fields=['priority'])
                
        self.logger.info(f"[PRIORITY] ‚úÖ –ü—Ä—ñ–æ—Ä–∏—Ç–∏–∑–∞—Ü—ñ—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {top_count} —Ç–æ–ø-—Å—Ç–∞—Ç–µ–π")

    def _calculate_article_score(self, article) -> float:
        """–†–æ–∑—Ä–∞—Ö–æ–≤—É—î —Å–∫–æ—Ä —Å—Ç–∞—Ç—Ç—ñ –¥–ª—è –ø—Ä—ñ–æ—Ä–∏—Ç–∏–∑–∞—Ü—ñ—ó (0-100)"""
        score = 50.0  # –ë–∞–∑–æ–≤–∏–π —Å–∫–æ—Ä
        
        try:
            # –§–∞–∫—Ç–æ—Ä–∏ —è–∫–æ—Å—Ç—ñ –∫–æ–Ω—Ç–µ–Ω—Ç—É
            content_length = len(article.summary_uk or "")
            if content_length > 2000:
                score += 15  # –î–æ–≤–≥–∏–π —è–∫—ñ—Å–Ω–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç
            elif content_length > 1000:
                score += 10
            elif content_length < 500:
                score -= 10  # –ö–æ—Ä–æ—Ç–∫–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç
            
            # –ù–∞—è–≤–Ω—ñ—Å—Ç—å –±—ñ–∑–Ω–µ—Å-—ñ–Ω—Å–∞–π—Ç—ñ–≤
            if article.business_insight_uk and len(article.business_insight_uk) > 50:
                score += 10
                
            if article.business_opportunities_uk and len(article.business_opportunities_uk) > 50:
                score += 10
                
            if article.lazysoft_recommendations_uk and len(article.lazysoft_recommendations_uk) > 50:
                score += 10
            
            # –ö–∞—Ç–µ–≥–æ—Ä—ñ—è (–¥–µ—è–∫—ñ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó –≤–∞–∂–ª–∏–≤—ñ—à—ñ)
            if hasattr(article, 'category') and article.category:
                high_priority_categories = ['ai', 'automation', 'fintech']
                if article.category.slug in high_priority_categories:
                    score += 15
                elif article.category.slug == 'general':
                    score -= 5
            
            # –ù–∞—è–≤–Ω—ñ—Å—Ç—å –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
            if article.ai_image_url:
                score += 5
            
            # –°–≤—ñ–∂—ñ—Å—Ç—å (–Ω–æ–≤—ñ—à—ñ —Å—Ç–∞—Ç—Ç—ñ –∫—Ä–∞—â—ñ)
            if hasattr(article, 'created_at'):
                from django.utils import timezone
                from datetime import timedelta
                
                age = timezone.now() - article.created_at
                if age < timedelta(hours=6):
                    score += 10  # –î—É–∂–µ —Å–≤—ñ–∂–∞
                elif age < timedelta(hours=24):
                    score += 5   # –°–≤—ñ–∂–∞
                elif age > timedelta(days=3):
                    score -= 5   # –°—Ç–∞—Ä–∞
            
            # –ö–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞ –≤ –∑–∞–≥–æ–ª–æ–≤–∫—É
            title = (article.title_uk or "").lower()
            high_value_keywords = [
                'google', 'microsoft', 'apple', 'openai', 'chatgpt', 
                'automation', 'ai', 'breakthrough', 'launch', 'new'
            ]
            
            for keyword in high_value_keywords:
                if keyword in title:
                    score += 8
                    
            # –û–±–º–µ–∂—É—î–º–æ —Å–∫–æ—Ä –¥—ñ–∞–ø–∞–∑–æ–Ω–æ–º 0-100
            score = max(0, min(100, score))
            
        except Exception as e:
            self.logger.warning(f"[SCORE] –ü–æ–º–∏–ª–∫–∞ —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É —Å–∫–æ—Ä—É: {e}")
            score = 50  # –î–µ—Ñ–æ–ª—Ç–Ω–∏–π —Å–∫–æ—Ä –ø—Ä–∏ –ø–æ–º–∏–ª—Ü—ñ
            
        return score
