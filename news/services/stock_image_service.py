# news/services/stock_image_service.py
"""
–°–µ—Ä–≤—ñ—Å –¥–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è —Å—Ç–æ–∫–æ–≤–∏—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å –∑ –±–µ–∑–∫–æ—à—Ç–æ–≤–Ω–∏—Ö API
"""

import requests
import logging
from typing import Optional, Dict, List
from django.conf import settings
from django.core.cache import cache
import hashlib

logger = logging.getLogger(__name__)


class StockImageService:
    """–°–µ—Ä–≤—ñ—Å –¥–ª—è –ø–æ—à—É–∫—É —Ç–∞ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è —Å—Ç–æ–∫–æ–≤–∏—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.timeout = 15
        
        # API –∫–ª—é—á—ñ –∑ settings
        self.unsplash_key = getattr(settings, 'UNSPLASH_ACCESS_KEY', None)
        self.pexels_key = getattr(settings, 'PEXELS_API_KEY', None)
        self.pixabay_key = getattr(settings, 'PIXABAY_API_KEY', None)
        
        # –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –∫–µ—à—É–≤–∞–Ω–Ω—è (30 –¥–Ω—ñ–≤)
        self.cache_timeout = 60 * 60 * 24 * 30
        
    def get_image_for_article(self, 
                            title: str, 
                            category: str = "general", 
                            keywords: List[str] = None) -> Optional[str]:
        """
        –ì–æ–ª–æ–≤–Ω–∏–π –º–µ—Ç–æ–¥ - —à—É–∫–∞—î –ø—ñ–¥—Ö–æ–¥—è—â–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –¥–ª—è —Å—Ç–∞—Ç—Ç—ñ
        
        Args:
            title: –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç–∞—Ç—Ç—ñ
            category: –ö–∞—Ç–µ–≥–æ—Ä—ñ—è –Ω–æ–≤–∏–Ω–∏
            keywords: –î–æ–¥–∞—Ç–∫–æ–≤—ñ –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞
            
        Returns:
            URL –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∞–±–æ None
        """
        logger.info(f"üñºÔ∏è –ü–æ—à—É–∫ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –¥–ª—è —Å—Ç–∞—Ç—Ç—ñ: {title[:50]}...")
        
        # –§–æ—Ä–º—É—î–º–æ –ø–æ—à—É–∫–æ–≤—ñ –∑–∞–ø–∏—Ç–∏
        search_queries = self._build_search_queries(title, category, keywords)
        
        # –ö–µ—à—É–≤–∞–Ω–Ω—è –ø–æ —Ö–µ—à—É –∑–∞–ø–∏—Ç—É
        cache_key = self._get_cache_key(search_queries[0])
        cached_url = cache.get(cache_key)
        if cached_url:
            logger.info("‚úÖ –ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑–Ω–∞–π–¥–µ–Ω–æ –≤ –∫–µ—à—ñ")
            return cached_url
        
        # –ü—Ä–æ–±—É—î–º–æ —Ä—ñ–∑–Ω—ñ API –ø–æ —á–µ—Ä–∑—ñ
        for query in search_queries:
            image_url = self._try_all_apis(query)
            if image_url:
                # –ö–µ—à—É—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                cache.set(cache_key, image_url, self.cache_timeout)
                logger.info(f"‚úÖ –ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑–Ω–∞–π–¥–µ–Ω–æ: {image_url}")
                return image_url
        
        logger.warning("‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ –ø—ñ–¥—Ö–æ–¥—è—â–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è")
        return None
    
    def _build_search_queries(self, title: str, category: str, keywords: List[str] = None) -> List[str]:
        """–°—Ç–≤–æ—Ä—é—î —Å–ø–∏—Å–æ–∫ –ø–æ—à—É–∫–æ–≤–∏—Ö –∑–∞–ø–∏—Ç—ñ–≤ –ø–æ –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç—É"""
        queries = []
        
        # –ú–∞–ø–ø—ñ–Ω–≥ –∫–∞—Ç–µ–≥–æ—Ä—ñ–π –Ω–∞ –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞
        category_mapping = {
            'ai': ['artificial intelligence', 'machine learning', 'technology', 'robot'],
            'automation': ['business automation', 'workflow', 'efficiency', 'technology'],
            'crm': ['customer management', 'business', 'sales', 'team'],
            'seo': ['digital marketing', 'analytics', 'growth', 'online'],
            'social': ['social media', 'marketing', 'communication', 'network'],
            'chatbots': ['chatbot', 'ai assistant', 'customer service', 'technology'],
            'ecommerce': ['online shopping', 'ecommerce', 'business', 'retail'],
            'fintech': ['finance', 'banking', 'money', 'technology'],
            'corporate': ['business', 'office', 'corporate', 'professional'],
            'general': ['technology', 'business', 'innovation', 'modern']
        }
        
        # 1. –ö–∞—Ç–µ–≥–æ—Ä—ñ—è + –æ—Å–Ω–æ–≤–Ω—ñ —Å–ª–æ–≤–∞ –∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞
        category_words = category_mapping.get(category, ['technology', 'business'])
        title_words = self._extract_keywords_from_title(title)
        
        if title_words:
            queries.append(f"{category_words[0]} {title_words[0]}")
        
        # 2. –¢—ñ–ª—å–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä—ñ—è
        queries.append(category_words[0])
        
        # 3. –î–æ–¥–∞—Ç–∫–æ–≤—ñ –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞
        if keywords:
            for keyword in keywords[:2]:  # –¢—ñ–ª—å–∫–∏ –ø–µ—Ä—à—ñ 2
                queries.append(keyword)
        
        # 4. –§–æ–ª–ª–±–µ–∫
        queries.append("business technology")
        
        return queries
    
    def _extract_keywords_from_title(self, title: str) -> List[str]:
        """–í–∏—Ç—è–≥—É—î –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞ –∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞ —Å—Ç–∞—Ç—Ç—ñ"""
        import re
        
        # –°—Ç–æ–ø-—Å–ª–æ–≤–∞ —è–∫—ñ —ñ–≥–Ω–æ—Ä—É—î–º–æ
        stop_words = {
            'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 
            'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'being',
            'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could',
            'should', 'may', 'might', 'can', 'this', 'that', 'these', 'those'
        }
        
        # –í–∏—Ç—è–≥—É—î–º–æ —Å–ª–æ–≤–∞
        words = re.findall(r'\b[a-zA-Z]{3,}\b', title.lower())
        keywords = [word for word in words if word not in stop_words]
        
        return keywords[:3]  # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ —Ç—ñ–ª—å–∫–∏ —Ç–æ–ø-3
    
    def _try_all_apis(self, query: str) -> Optional[str]:
        """–ü—Ä–æ–±—É—î –≤—Å—ñ –¥–æ—Å—Ç—É–ø–Ω—ñ API –ø–æ —á–µ—Ä–∑—ñ"""
        
        # 1. Unsplash (–Ω–∞–π–∫—Ä–∞—â–∞ —è–∫—ñ—Å—Ç—å)
        if self.unsplash_key:
            url = self._search_unsplash(query)
            if url:
                return url
        
        # 2. Pexels (–±—ñ–ª—å—à–µ –∑–∞–ø–∏—Ç—ñ–≤)
        if self.pexels_key:
            url = self._search_pexels(query)
            if url:
                return url
        
        # 3. Pixabay (–Ω–∞–π–±—ñ–ª—å—à–∞ –±–∞–∑–∞)
        if self.pixabay_key:
            url = self._search_pixabay(query)
            if url:
                return url
        
        return None
    
    def _search_unsplash(self, query: str) -> Optional[str]:
        """–ü–æ—à—É–∫ –≤ Unsplash API"""
        try:
            logger.info(f"üîç Unsplash –ø–æ—à—É–∫: {query}")
            response = self.session.get(
                "https://api.unsplash.com/search/photos",
                headers={"Authorization": f"Client-ID {self.unsplash_key}"},
                params={
                    "query": query,
                    "per_page": 5,
                    "orientation": "landscape",
                    "order_by": "relevant"
                }
            )
            
            if response.status_code == 200:
                data = response.json()
                if data['results']:
                    # –ë–µ—Ä–µ–º–æ –ø–µ—Ä—à–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –≤ —Å–µ—Ä–µ–¥–Ω—ñ–π —è–∫–æ—Å—Ç—ñ
                    image = data['results'][0]
                    logger.info(f"‚úÖ Unsplash –∑–Ω–∞–π—à–æ–≤ {len(data['results'])} –∑–æ–±—Ä–∞–∂–µ–Ω—å")
                    return image['urls']['regular']  # 1080px —à–∏—Ä–∏–Ω–∞
                else:
                    logger.warning(f"‚ö†Ô∏è Unsplash: –Ω–µ–º–∞—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –¥–ª—è '{query}'")
            else:
                logger.error(f"‚ùå Unsplash API –ø–æ–º–∏–ª–∫–∞: {response.status_code} - {response.text}")
                    
        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ Unsplash API: {e}")
        
        return None
    
    def _search_pexels(self, query: str) -> Optional[str]:
        """–ü–æ—à—É–∫ –≤ Pexels API"""
        try:
            response = self.session.get(
                "https://api.pexels.com/v1/search",
                headers={"Authorization": self.pexels_key},
                params={
                    "query": query,
                    "per_page": 5,
                    "orientation": "landscape"
                }
            )
            
            if response.status_code == 200:
                data = response.json()
                if data['photos']:
                    # –ë–µ—Ä–µ–º–æ —Å–µ—Ä–µ–¥–Ω—ñ–π —Ä–æ–∑–º—ñ—Ä
                    photo = data['photos'][0]
                    return photo['src']['large']  # 1880px —à–∏—Ä–∏–Ω–∞
                    
        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ Pexels API: {e}")
        
        return None
    
    def _search_pixabay(self, query: str) -> Optional[str]:
        """–ü–æ—à—É–∫ –≤ Pixabay API"""
        try:
            response = self.session.get(
                "https://pixabay.com/api/",
                params={
                    "key": self.pixabay_key,
                    "q": query,
                    "image_type": "photo",
                    "orientation": "horizontal",
                    "category": "business",
                    "min_width": 1000,
                    "per_page": 5
                }
            )
            
            if response.status_code == 200:
                data = response.json()
                if data['hits']:
                    # –ë–µ—Ä–µ–º–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Å–µ—Ä–µ–¥–Ω—å–æ—ó —è–∫–æ—Å—Ç—ñ
                    image = data['hits'][0]
                    return image['webformatURL']  # 640px —à–∏—Ä–∏–Ω–∞
                    
        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ Pixabay API: {e}")
        
        return None
    
    def _get_cache_key(self, query: str) -> str:
        """–°—Ç–≤–æ—Ä—é—î –∫–ª—é—á –¥–ª—è –∫–µ—à—É–≤–∞–Ω–Ω—è"""
        query_hash = hashlib.md5(query.encode()).hexdigest()[:16]
        return f"stock_image:{query_hash}"


# Singleton —ñ–Ω—Å—Ç–∞–Ω—Å –¥–ª—è –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –≤ –ø—Ä–æ–µ–∫—Ç—ñ
stock_image_service = StockImageService()

