# rag/services.py
import os
import json
import logging
from typing import List, Dict, Tuple, Optional
from django.conf import settings
from django.db.models import Q
from django.contrib.contenttypes.models import ContentType
from pgvector.django import CosineDistance
import google.generativeai as genai
from openai import OpenAI

from .models import EmbeddingModel, ChatSession, ChatMessage, RAGAnalytics
from services.models import ServiceCategory, FAQ
from projects.models import Project
from pricing.models import ServicePricing

logger = logging.getLogger(__name__)


class EmbeddingService:
    """–°–µ—Ä–≤—ñ—Å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó —Ç–∞ —É–ø—Ä–∞–≤–ª—ñ–Ω–Ω—è embedding'–∞–º–∏"""
    
    def __init__(self):
        self.gemini_api_key = getattr(settings, 'GEMINI_API_KEY', None)
        self.openai_api_key = getattr(settings, 'OPENAI_API_KEY', None)
        
        # –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –∑ settings
        self.rag_settings = getattr(settings, 'RAG_SETTINGS', {})
        self.embedding_model = self.rag_settings.get('EMBEDDING_MODEL', 'gemini')
        
        # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è AI –∫–ª—ñ—î–Ω—Ç—ñ–≤
        if self.embedding_model == 'gemini' and self.gemini_api_key:
            genai.configure(api_key=self.gemini_api_key)
            
        if self.openai_api_key:
            self.openai_client = OpenAI(api_key=self.openai_api_key)
    
    def generate_embedding(self, text: str, model: str = None) -> List[float]:
        """–ì–µ–Ω–µ—Ä—É—î embedding –¥–ª—è —Ç–µ–∫—Å—Ç—É"""
        if not text.strip():
            raise ValueError("–¢–µ–∫—Å—Ç –Ω–µ –º–æ–∂–µ –±—É—Ç–∏ –ø—É—Å—Ç–∏–º")
            
        model = model or self.embedding_model
        
        try:
            if model == 'gemini':
                return self._generate_gemini_embedding(text)
            elif model == 'openai':
                return self._generate_openai_embedding(text)
            else:
                raise ValueError(f"–ù–µ–≤—ñ–¥–æ–º–∞ –º–æ–¥–µ–ª—å: {model}")
                
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó embedding: {e}")
            raise
    
    def _generate_gemini_embedding(self, text: str) -> List[float]:
        """–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è embedding —á–µ—Ä–µ–∑ Gemini"""
        model = self.rag_settings.get('GEMINI_EMBEDDING_MODEL', 'models/embedding-001')
        
        response = genai.embed_content(
            model=model,
            content=text,
            task_type="retrieval_document"
        )
        
        return response['embedding']
    
    def _generate_openai_embedding(self, text: str) -> List[float]:
        """–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è embedding —á–µ—Ä–µ–∑ OpenAI"""
        model = self.rag_settings.get('OPENAI_EMBEDDING_MODEL', 'text-embedding-3-small')
        
        response = self.openai_client.embeddings.create(
            model=model,
            input=text
        )
        
        return response.data[0].embedding
    
    def create_embedding_for_object(self, obj, language: str = 'uk') -> EmbeddingModel:
        """–°—Ç–≤–æ—Ä—é—î embedding –¥–ª—è Django –æ–±'—î–∫—Ç–∞"""
        content_type = ContentType.objects.get_for_model(obj)
        
        # –í–∏—Ç—è–≥—É—î–º–æ —Ç–µ–∫—Å—Ç –∑ –æ–±'—î–∫—Ç–∞
        text_content = self._extract_text_from_object(obj, language)
        title = self._extract_title_from_object(obj, language)
        category = self._extract_category_from_object(obj)
        
        if not text_content:
            logger.warning(f"–ù–µ–º–∞—î —Ç–µ–∫—Å—Ç—É –¥–ª—è —ñ–Ω–¥–µ–∫—Å–∞—Ü—ñ—ó: {obj}")
            return None
        
        # –ì–µ–Ω–µ—Ä—É—î–º–æ embedding
        try:
            embedding_vector = self.generate_embedding(text_content)
        except Exception as e:
            logger.error(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ embedding –¥–ª—è {obj}: {e}")
            raise
        
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∞–±–æ –æ–Ω–æ–≤–ª—é—î–º–æ
        embedding_obj, created = EmbeddingModel.objects.update_or_create(
            content_type=content_type,
            object_id=obj.pk,
            language=language,
            defaults={
                'embedding': embedding_vector,
                'content_text': text_content[:5000],  # –û–±–º–µ–∂—É—î–º–æ –¥–æ–≤–∂–∏–Ω—É
                'content_title': title,
                'content_category': category,
                'model_name': f"{self.embedding_model}-embedding",
                'is_active': True,
            }
        )
        
        action = "—Å—Ç–≤–æ—Ä–µ–Ω–æ" if created else "–æ–Ω–æ–≤–ª–µ–Ω–æ"
        logger.info(f"Embedding {action} –¥–ª—è {obj} ({language})")
        
        return embedding_obj
    
    def _extract_text_from_object(self, obj, language: str) -> str:
        """–í–∏—Ç—è–≥—É—î —Ç–µ–∫—Å—Ç –∑ Django –æ–±'—î–∫—Ç–∞ –¥–ª—è —ñ–Ω–¥–µ–∫—Å–∞—Ü—ñ—ó"""
        text_parts = []
        
        if isinstance(obj, ServiceCategory):
            title = getattr(obj, f'title_{language}', obj.title_en)
            description = getattr(obj, f'description_{language}', obj.description_en)
            short_desc = getattr(obj, f'short_description_{language}', obj.short_description_en)
            target_audience = getattr(obj, f'target_audience_{language}', obj.target_audience_en)
            value_prop = getattr(obj, f'value_proposition_{language}', obj.value_proposition_en)
            
            if title: text_parts.append(f"–°–µ—Ä–≤—ñ—Å: {title}")
            if description: text_parts.append(description)
            if short_desc: text_parts.append(short_desc)
            if target_audience: text_parts.append(f"–î–ª—è –∫–æ–≥–æ: {target_audience}")
            if value_prop: text_parts.append(f"–ü–µ—Ä–µ–≤–∞–≥–∏: {value_prop}")
            
        elif isinstance(obj, Project):
            title = getattr(obj, f'title_{language}', obj.title_en)
            short_desc = getattr(obj, f'short_description_{language}', obj.short_description_en)
            client_request = getattr(obj, f'client_request_{language}', obj.client_request_en)
            implementation = getattr(obj, f'implementation_{language}', obj.implementation_en)
            results = getattr(obj, f'results_{language}', obj.results_en)
            
            if title: text_parts.append(f"–ü—Ä–æ—î–∫—Ç: {title}")
            if short_desc: text_parts.append(short_desc)
            if client_request: text_parts.append(f"–ó–∞–≤–¥–∞–Ω–Ω—è: {client_request}")
            if implementation: text_parts.append(f"–†—ñ—à–µ–Ω–Ω—è: {implementation}")
            if results: text_parts.append(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {results}")
            
        elif isinstance(obj, FAQ):
            question = getattr(obj, f'question_{language}', obj.question_en)
            answer = getattr(obj, f'answer_{language}', obj.answer_en)
            
            if question: text_parts.append(f"–ü–∏—Ç–∞–Ω–Ω—è: {question}")
            if answer: text_parts.append(f"–í—ñ–¥–ø–æ–≤—ñ–¥—å: {answer}")
        
        return '\n'.join(text_parts)
    
    def _extract_title_from_object(self, obj, language: str) -> str:
        """–í–∏—Ç—è–≥—É—î –∑–∞–≥–æ–ª–æ–≤–æ–∫ –æ–±'—î–∫—Ç–∞"""
        if hasattr(obj, f'title_{language}'):
            return getattr(obj, f'title_{language}') or getattr(obj, 'title_en', str(obj))
        elif hasattr(obj, f'question_{language}'):  # FAQ
            return getattr(obj, f'question_{language}') or getattr(obj, 'question_en', str(obj))
        return str(obj)
    
    def _extract_category_from_object(self, obj) -> str:
        """–í–∏—Ç—è–≥—É—î –∫–∞—Ç–µ–≥–æ—Ä—ñ—é –æ–±'—î–∫—Ç–∞"""
        if isinstance(obj, ServiceCategory):
            return 'service'
        elif isinstance(obj, Project):
            return 'project'
        elif isinstance(obj, FAQ):
            return 'faq'
        return 'unknown'


class VectorSearchService:
    """–°–µ—Ä–≤—ñ—Å –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ—à—É–∫—É"""
    
    def __init__(self):
        self.embedding_service = EmbeddingService()
        self.rag_settings = getattr(settings, 'RAG_SETTINGS', {})
        
    def search_similar_content(
        self, 
        query: str, 
        language: str = 'uk',
        limit: int = None,
        category: str = None,
        threshold: float = None
    ) -> List[Dict]:
        """–®—É–∫–∞—î —Å—Ö–æ–∂–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ—à—É–∫—É"""
        
        limit = limit or self.rag_settings.get('MAX_SEARCH_RESULTS', 10)
        threshold = threshold or self.rag_settings.get('SIMILARITY_THRESHOLD', 0.7)
        
        # –ì–µ–Ω–µ—Ä—É—î–º–æ embedding –¥–ª—è –∑–∞–ø–∏—Ç—É
        try:
            query_embedding = self.embedding_service.generate_embedding(query)
        except Exception as e:
            logger.error(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ embedding –¥–ª—è –∑–∞–ø–∏—Ç—É '{query}': {e}")
            return []
        
        # –ë—É–¥—É—î–º–æ –∑–∞–ø–∏—Ç –¥–æ –ë–î
        queryset = EmbeddingModel.objects.filter(
            is_active=True,
            language=language
        )
        
        if category:
            queryset = queryset.filter(content_category=category)
        
        # –í–µ–∫—Ç–æ—Ä–Ω–∏–π –ø–æ—à—É–∫ –∑ cosine distance
        results = queryset.annotate(
            distance=CosineDistance('embedding', query_embedding)
        ).filter(
            distance__lt=(1 - threshold)  # Cosine distance: –º–µ–Ω—à–µ = —Å—Ö–æ–∂—ñ—à–µ
        ).order_by('distance')[:limit]
        
        # –§–æ—Ä–º–∞—Ç—É—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
        formatted_results = []
        for result in results:
            similarity = 1 - float(result.distance)  # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ distance –Ω–∞–∑–∞–¥ –≤ similarity
            
            formatted_results.append({
                'object': result.content_object,
                'content_text': result.content_text,
                'content_title': result.content_title,
                'content_category': result.content_category,
                'similarity': round(similarity, 3),
                'metadata': result.metadata,
            })
        
        logger.info(f"Vector search –¥–ª—è '{query}': –∑–Ω–∞–π–¥–µ–Ω–æ {len(formatted_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤")
        return formatted_results


class RAGConsultantService:
    """–ì–æ–ª–æ–≤–Ω–∏–π RAG –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç"""
    
    def __init__(self):
        self.vector_search = VectorSearchService()
        self.embedding_service = EmbeddingService()
        self.rag_settings = getattr(settings, 'RAG_SETTINGS', {})
        
        # AI –∫–ª—ñ—î–Ω—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π
        self.gemini_api_key = getattr(settings, 'GEMINI_API_KEY', None)
        if self.gemini_api_key:
            genai.configure(api_key=self.gemini_api_key)
    
    def process_user_query(
        self, 
        query: str, 
        session_id: str,
        language: str = 'uk'
    ) -> Dict:
        """–û–±—Ä–æ–±–ª—è—î –∑–∞–ø–∏—Ç –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ —á–µ—Ä–µ–∑ RAG"""
        
        # –û—Ç—Ä–∏–º—É—î–º–æ –∞–±–æ —Å—Ç–≤–æ—Ä—é—î–º–æ —Å–µ—Å—ñ—é
        session, created = ChatSession.objects.get_or_create(
            session_id=session_id,
            defaults={'detected_intent': 'general'}
        )
        
        # –í–µ–∫—Ç–æ—Ä–Ω–∏–π –ø–æ—à—É–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç—É
        search_results = self.vector_search.search_similar_content(
            query=query,
            language=language,
            limit=5
        )
        
        # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ –Ω–∞–º—ñ—Ä –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
        detected_intent = self._detect_user_intent(query, search_results)
        session.detected_intent = detected_intent
        session.total_messages += 1
        session.save()
        
        # –ì–µ–Ω–µ—Ä—É—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∑–Ω–∞–π–¥–µ–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç—É
        response = self._generate_rag_response(
            query=query,
            search_results=search_results,
            language=language,
            intent=detected_intent
        )
        
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è
        ChatMessage.objects.create(
            session=session,
            role='user',
            content=query
        )
        
        ChatMessage.objects.create(
            session=session,
            role='assistant', 
            content=response['content'],
            rag_sources_used=[r['content_title'] for r in search_results],
            vector_search_results=search_results,
            ai_model_used='gemini-pro'
        )
        
        return {
            'response': response['content'],
            'intent': detected_intent,
            'sources': search_results,
            'suggestions': response.get('suggestions', []),
            'session_id': session_id
        }
    
    def _detect_user_intent(self, query: str, search_results: List[Dict]) -> str:
        """–í–∏–∑–Ω–∞—á–∞—î –Ω–∞–º—ñ—Ä –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞"""
        query_lower = query.lower()
        
        # –ö–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –Ω–∞–º—ñ—Ä—É
        if any(word in query_lower for word in ['—Ü—ñ–Ω–∞', '—Å–∫—ñ–ª—å–∫–∏', '–∫–æ—à—Ç—É—î', '–±—é–¥–∂–µ—Ç', 'price']):
            return 'pricing'
        elif any(word in query_lower for word in ['–∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü—ñ—è', '–∑—É—Å—Ç—Ä—ñ—á', '–ø–æ–≥–æ–≤–æ—Ä–∏—Ç–∏', 'consultation']):
            return 'consultation'
        elif any(word in query_lower for word in ['–ø—Ä–æ—î–∫—Ç', '–ø–æ—Ä—Ç—Ñ–æ–ª—ñ–æ', '–∫–µ–π—Å', '–ø—Ä–∏–∫–ª–∞–¥', 'project']):
            return 'portfolio'
        elif search_results and search_results[0]['content_category'] == 'service':
            return 'services'
        else:
            return 'general'
    
    def _generate_rag_response(
        self, 
        query: str, 
        search_results: List[Dict],
        language: str,
        intent: str
    ) -> Dict:
        """–ì–µ–Ω–µ—Ä—É—î –≤—ñ–¥–ø–æ–≤—ñ–¥—å –Ω–∞ –æ—Å–Ω–æ–≤—ñ RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç—É"""
        
        if not search_results:
            return self._generate_fallback_response(query, language, intent)
        
        # –ë—É–¥—É—î–º–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç –∑ –Ω–∞–π–∫—Ä–∞—â–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        context_parts = []
        for result in search_results[:3]:  # –¢–æ–ø 3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
            context_parts.append(f"""
–î–∂–µ—Ä–µ–ª–æ: {result['content_title']} (—Å—Ö–æ–∂—ñ—Å—Ç—å: {result['similarity']})
–¢–∏–ø: {result['content_category']}
–ö–æ–Ω—Ç–µ–Ω—Ç: {result['content_text'][:800]}
""")
        
        context = "\n---\n".join(context_parts)
        
        # –ü—Ä–æ–º–ø—Ç –¥–ª—è Gemini
        system_prompt = self._get_system_prompt(language, intent)
        user_prompt = f"""
–ö–æ–Ω—Ç–µ–∫—Å—Ç –∑ –±–∞–∑–∏ –∑–Ω–∞–Ω—å:
{context}

–ó–∞–ø–∏—Ç –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞: {query}

–î–∞–π –≤—ñ–¥–ø–æ–≤—ñ–¥—å —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é –Ω–∞ –æ—Å–Ω–æ–≤—ñ –Ω–∞–¥–∞–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É. –ë—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ—é —Ç–∞ –∫–æ—Ä–∏—Å–Ω–æ—é.
"""
        
        try:
            # –ì–µ–Ω–µ—Ä—É—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å —á–µ—Ä–µ–∑ Gemini
            model = genai.GenerativeModel('gemini-pro')
            response = model.generate_content(
                f"{system_prompt}\n\n{user_prompt}",
                generation_config=genai.types.GenerationConfig(
                    temperature=0.7,
                    max_output_tokens=1000,
                )
            )
            
            ai_response = response.text
            
            # –î–æ–¥–∞—î–º–æ –ø–µ—Ä—Å–æ–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ –ø—Ä–æ–ø–æ–∑–∏—Ü—ñ—ó
            suggestions = self._generate_suggestions(intent, search_results, language)
            
            return {
                'content': ai_response,
                'suggestions': suggestions,
                'context_used': len(search_results)
            }
            
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó RAG –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ: {e}")
            return self._generate_fallback_response(query, language, intent)
    
    def _get_system_prompt(self, language: str, intent: str) -> str:
        """–ü–æ–≤–µ—Ä—Ç–∞—î —Å–∏—Å—Ç–µ–º–Ω–∏–π –ø—Ä–æ–º–ø—Ç –∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ –Ω–∞–º—ñ—Ä—É"""
        
        consultant_name = self.rag_settings.get('CONSULTANT_NAME', '–Æ–ª—ñ—è')
        
        base_prompt = f"""
–¢–∏ - {consultant_name}, –¥–æ—Å–≤—ñ–¥—á–µ–Ω–∞ IT –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç–∫–∞ –∫–æ–º–ø–∞–Ω—ñ—ó LazySoft. 
–¢–∏ –¥–æ–ø–æ–º–∞–≥–∞—î—à –∫–ª—ñ—î–Ω—Ç–∞–º –∑ —Ç–µ—Ö–Ω—ñ—á–Ω–∏–º–∏ —Ä—ñ—à–µ–Ω–Ω—è–º–∏ —Ç–∞ –±—ñ–∑–Ω–µ—Å-–∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü—ñ—î—é.

–¢–≤–æ—è –ø–æ–≤–µ–¥—ñ–Ω–∫–∞:
- –í—ñ–¥–ø–æ–≤—ñ–¥–∞–π –ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–æ, –∞–ª–µ –¥—Ä—É–∂–µ–ª—é–±–Ω–æ
- –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ñ —Ñ–∞–∫—Ç–∏ –∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
- –ü—Ä–æ–ø–æ–Ω—É–π –ø—Ä–∞–∫—Ç–∏—á–Ω—ñ —Ä—ñ—à–µ–Ω–Ω—è
- –ó–∞–≤–∂–¥–∏ –∑–≥–∞–¥—É–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ –ø—Ä–æ—î–∫—Ç–∏ –∞–±–æ —Å–µ—Ä–≤—ñ—Å–∏
"""
        
        intent_prompts = {
            'pricing': f"""
{base_prompt}
–§–æ–∫—É—Å –Ω–∞ —Ü—ñ–Ω–∏: –ö–æ–ª–∏ –≥–æ–≤–æ—Ä–∏—à –ø—Ä–æ —Ü—ñ–Ω–∏, –∑–∞–≤–∂–¥–∏:
1. –£—Ç–æ—á–Ω—é–π –¥–µ—Ç–∞–ª—ñ –ø—Ä–æ—î–∫—Ç—É –ø–µ—Ä–µ–¥ –Ω–∞–∑–∏–≤–∞–Ω–Ω—è–º —Ü—ñ–Ω
2. –ü—Ä–æ–ø–æ–Ω—É–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ñ –ø–∞–∫–µ—Ç–∏ (–±–∞–∑–æ–≤–∏–π/—Å—Ç–∞–Ω–¥–∞—Ä—Ç/–ø—Ä–µ–º—ñ—É–º)
3. –ó–≥–∞–¥—É–π –ø—Ä–∏–∫–ª–∞–¥–∏ —Å—Ö–æ–∂–∏—Ö –ø—Ä–æ—î–∫—Ç—ñ–≤
4. –ü—Ä–æ–ø–æ–Ω—É–π –±–µ–∑–∫–æ—à—Ç–æ–≤–Ω—É –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü—ñ—é –∞–±–æ –ø—Ä–æ—Ä–∞—Ö—É–Ω–æ–∫
""",
            'consultation': f"""
{base_prompt}
–§–æ–∫—É—Å –Ω–∞ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü—ñ—ó: 
1. –ü—ñ–¥–∫—Ä–µ—Å–ª—é–π –ø–µ—Ä–µ–≤–∞–≥–∏ –æ—Å–æ–±–∏—Å—Ç–æ–≥–æ —Å–ø—ñ–ª–∫—É–≤–∞–Ω–Ω—è
2. –ü—Ä–æ–ø–æ–Ω—É–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ñ —á–∞—Å–∏ –¥–ª—è –∑—É—Å—Ç—Ä—ñ—á—ñ
3. –ì–æ—Ç—É–π —Å–ø–∏—Å–æ–∫ –ø–∏—Ç–∞–Ω—å –¥–ª—è –∫—Ä–∞—â–æ—ó –ø—ñ–¥–≥–æ—Ç–æ–≤–∫–∏
""",
            'services': f"""
{base_prompt}
–§–æ–∫—É—Å –Ω–∞ —Å–µ—Ä–≤—ñ—Å–∏:
1. –î–µ—Ç–∞–ª—å–Ω–æ —Ä–æ–∑–ø–æ–≤—ñ–¥–∞–π –ø—Ä–æ –º–æ–∂–ª–∏–≤–æ—Å—Ç—ñ
2. –ù–∞–≤–æ–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ñ –ø—Ä–∏–∫–ª–∞–¥–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è  
3. –ü—Ä–æ–ø–æ–Ω—É–π —Å—É–ø—É—Ç–Ω—ñ –ø–æ—Å–ª—É–≥–∏
""",
            'portfolio': f"""
{base_prompt}
–§–æ–∫—É—Å –Ω–∞ –ø—Ä–æ—î–∫—Ç–∏:
1. –†–æ–∑–ø–æ–≤—ñ–¥–∞–π –ø—Ä–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ñ –∫–µ–π—Å–∏
2. –ü—ñ–¥–∫—Ä–µ—Å–ª—é–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ —Ç–∞ ROI
3. –ü—Ä–æ–ø–æ–Ω—É–π —Å—Ö–æ–∂—ñ —Ä—ñ—à–µ–Ω–Ω—è
""",
        }
        
        return intent_prompts.get(intent, base_prompt)
    
    def _generate_suggestions(self, intent: str, search_results: List[Dict], language: str) -> List[str]:
        """–ì–µ–Ω–µ—Ä—É—î –ø–µ—Ä—Å–æ–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ –ø—Ä–æ–ø–æ–∑–∏—Ü—ñ—ó"""
        
        suggestions = []
        
        if intent == 'pricing':
            suggestions = [
                "üßÆ –û—Ç—Ä–∏–º–∞—Ç–∏ –¥–µ—Ç–∞–ª—å–Ω–∏–π –ø—Ä–æ—Ä–∞—Ö—É–Ω–æ–∫",
                "üìÖ –ó–∞–ø–∏—Å–∞—Ç–∏—Å—è –Ω–∞ –±–µ–∑–∫–æ—à—Ç–æ–≤–Ω—É –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü—ñ—é",
                "üìã –ü–µ—Ä–µ–≥–ª—è–Ω—É—Ç–∏ —Å—Ö–æ–∂—ñ –ø—Ä–æ—î–∫—Ç–∏",
            ]
        elif intent == 'consultation':
            suggestions = [
                "üìÖ –û–±—Ä–∞—Ç–∏ –∑—Ä—É—á–Ω–∏–π —á–∞—Å –¥–ª—è –∑—É—Å—Ç—Ä—ñ—á—ñ",
                "üìù –ü—ñ–¥–≥–æ—Ç—É–≤–∞—Ç–∏ —Å–ø–∏—Å–æ–∫ –ø–∏—Ç–∞–Ω—å",
                "üíº –†–æ–∑–ø–æ–≤—ñ—Å—Ç–∏ –ø—Ä–æ –≤–∞—à –±—ñ–∑–Ω–µ—Å",
            ]
        elif intent == 'services':
            # –ü—Ä–æ–ø–æ–Ω—É—î–º–æ —Å—É–ø—É—Ç–Ω—ñ —Å–µ—Ä–≤—ñ—Å–∏
            if search_results:
                categories = set(r.get('content_category') for r in search_results)
                if 'service' in categories:
                    suggestions.extend([
                        "üîç –î—ñ–∑–Ω–∞—Ç–∏—Å—è –±—ñ–ª—å—à–µ –ø—Ä–æ —Ü–µ–π —Å–µ—Ä–≤—ñ—Å",
                        "üí∞ –ü–µ—Ä–µ–≥–ª—è–Ω—É—Ç–∏ –ø–∞–∫–µ—Ç–∏ —Ç–∞ —Ü—ñ–Ω–∏",
                        "üìû –û–±–≥–æ–≤–æ—Ä–∏—Ç–∏ –≤–∞—à—ñ –ø–æ—Ç—Ä–µ–±–∏",
                    ])
        elif intent == 'portfolio':
            suggestions = [
                "üìä –ü–µ—Ä–µ–≥–ª—è–Ω—É—Ç–∏ –¥–µ—Ç–∞–ª—å–Ω–∏–π –∫–µ–π—Å",
                "üí° –û–±–≥–æ–≤–æ—Ä–∏—Ç–∏ —Å—Ö–æ–∂–µ —Ä—ñ—à–µ–Ω–Ω—è",
                "üìà –î—ñ–∑–Ω–∞—Ç–∏—Å—è –ø—Ä–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏",
            ]
        else:
            suggestions = [
                "‚ùì –ü–æ—Å—Ç–∞–≤–∏—Ç–∏ —É—Ç–æ—á–Ω—é–≤–∞–ª—å–Ω–µ –ø–∏—Ç–∞–Ω–Ω—è",
                "üìû –ó–≤'—è–∑–∞—Ç–∏—Å—è –∑ –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç–æ–º",
                "üè† –ü–æ–≤–µ—Ä–Ω—É—Ç–∏—Å—è –Ω–∞ –≥–æ–ª–æ–≤–Ω—É",
            ]
        
        return suggestions
    
    def _generate_fallback_response(self, query: str, language: str, intent: str) -> Dict:
        """–ì–µ–Ω–µ—Ä—É—î –≤—ñ–¥–ø–æ–≤—ñ–¥—å –∫–æ–ª–∏ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç—É"""
        
        fallback_responses = {
            'uk': {
                'pricing': "–©–æ–± –¥–∞—Ç–∏ —Ç–æ—á–Ω—É —Ü—ñ–Ω—É, –º–µ–Ω—ñ –ø–æ—Ç—Ä—ñ–±–Ω–æ –±—ñ–ª—å—à–µ –¥–µ—Ç–∞–ª–µ–π –ø—Ä–æ –≤–∞—à –ø—Ä–æ—î–∫—Ç. –†–æ–∑–∫–∞–∂—ñ—Ç—å, –±—É–¥—å –ª–∞—Å–∫–∞, —â–æ —Å–∞–º–µ –≤–∞—Å —Ü—ñ–∫–∞–≤–∏—Ç—å?",
                'consultation': "–Ø –±—É–¥—É —Ä–∞–¥–∞ –æ–±–≥–æ–≤–æ—Ä–∏—Ç–∏ –≤–∞—à–µ –ø–∏—Ç–∞–Ω–Ω—è –Ω–∞ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü—ñ—ó. –ö–æ–ª–∏ –≤–∞–º –±—É–¥–µ –∑—Ä—É—á–Ω–æ –∑—É—Å—Ç—Ä—ñ—Ç–∏—Å—è?",
                'services': "–†–æ–∑–∫–∞–∂—ñ—Ç—å –±—ñ–ª—å—à–µ –ø—Ä–æ —Ç–µ, —â–æ –≤–∞—Å —Ü—ñ–∫–∞–≤–∏—Ç—å, —ñ —è –∑–º–æ–∂—É –∑–∞–ø—Ä–æ–ø–æ–Ω—É–≤–∞—Ç–∏ –Ω–∞–π–∫—Ä–∞—â–µ —Ä—ñ—à–µ–Ω–Ω—è.",
                'general': "–¶—ñ–∫–∞–≤–µ –ø–∏—Ç–∞–Ω–Ω—è! –©–æ–± –¥–∞—Ç–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∫–æ—Ä–∏—Å–Ω—É –≤—ñ–¥–ø–æ–≤—ñ–¥—å, —É—Ç–æ—á–Ω—ñ—Ç—å, –±—É–¥—å –ª–∞—Å–∫–∞, –¥–µ—Ç–∞–ª—ñ."
            }
        }
        
        response_text = fallback_responses.get(language, fallback_responses['uk']).get(intent, fallback_responses['uk']['general'])
        
        return {
            'content': response_text,
            'suggestions': [
                "üí¨ –£—Ç–æ—á–Ω–∏—Ç–∏ –ø–∏—Ç–∞–Ω–Ω—è",
                "üìû –ó–≤'—è–∑–∞—Ç–∏—Å—è –∑ –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç–æ–º", 
                "üìã –ü–µ—Ä–µ–≥–ª—è–Ω—É—Ç–∏ –Ω–∞—à—ñ —Å–µ—Ä–≤—ñ—Å–∏"
            ],
            'context_used': 0
        }


class IndexingService:
    """–°–µ—Ä–≤—ñ—Å –¥–ª—è —ñ–Ω–¥–µ–∫—Å–∞—Ü—ñ—ó –∫–æ–Ω—Ç–µ–Ω—Ç—É"""
    
    def __init__(self):
        self.embedding_service = EmbeddingService()
        self.rag_settings = getattr(settings, 'RAG_SETTINGS', {})
    
    def index_all_content(self):
        """–Ü–Ω–¥–µ–∫—Å—É—î –≤–µ—Å—å –∫–æ–Ω—Ç–µ–Ω—Ç –∑ –≤–∏–∑–Ω–∞—á–µ–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π"""
        
        indexable_models = self.rag_settings.get('INDEXABLE_MODELS', [])
        languages = self.rag_settings.get('SUPPORTED_LANGUAGES', ['uk'])
        
        total_indexed = 0
        
        for model_path in indexable_models:
            try:
                app_label, model_name = model_path.split('.')
                content_type = ContentType.objects.get(app_label=app_label, model=model_name.lower())
                model_class = content_type.model_class()
                
                objects = model_class.objects.filter(is_active=True) if hasattr(model_class, 'is_active') else model_class.objects.all()
                
                for obj in objects:
                    for lang in languages:
                        try:
                            self.embedding_service.create_embedding_for_object(obj, lang)
                            total_indexed += 1
                        except Exception as e:
                            logger.error(f"–ü–æ–º–∏–ª–∫–∞ —ñ–Ω–¥–µ–∫—Å–∞—Ü—ñ—ó {obj} ({lang}): {e}")
                            continue
                            
                logger.info(f"–Ü–Ω–¥–µ–∫—Å–æ–≤–∞–Ω–æ {objects.count()} –æ–±'—î–∫—Ç—ñ–≤ –∑ {model_path}")
                
            except Exception as e:
                logger.error(f"–ü–æ–º–∏–ª–∫–∞ —ñ–Ω–¥–µ–∫—Å–∞—Ü—ñ—ó –º–æ–¥–µ–ª—ñ {model_path}: {e}")
                continue
        
        logger.info(f"–ó–∞–≥–∞–ª–æ–º –ø—Ä–æ—ñ–Ω–¥–µ–∫—Å–æ–≤–∞–Ω–æ {total_indexed} –∑–∞–ø–∏—Å—ñ–≤")
        return total_indexed
    
    def reindex_object(self, obj):
        """–ü–µ—Ä–µ—ñ–Ω–¥–µ–∫—Å—É—î –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏–π –æ–±'—î–∫—Ç"""
        languages = self.rag_settings.get('SUPPORTED_LANGUAGES', ['uk'])
        
        for lang in languages:
            try:
                self.embedding_service.create_embedding_for_object(obj, lang)
            except Exception as e:
                logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø–µ—Ä–µ—ñ–Ω–¥–µ–∫—Å–∞—Ü—ñ—ó {obj} ({lang}): {e}")
    
    def cleanup_orphaned_embeddings(self):
        """–í–∏–¥–∞–ª—è—î embedding'–∏ –¥–ª—è –≤–∏–¥–∞–ª–µ–Ω–∏—Ö –æ–±'—î–∫—Ç—ñ–≤"""
        deleted_count = 0
        
        for embedding in EmbeddingModel.objects.all():
            if not embedding.content_object:  # –û–±'—î–∫—Ç –≤–∏–¥–∞–ª–µ–Ω–æ
                embedding.delete()
                deleted_count += 1
        
        logger.info(f"–í–∏–¥–∞–ª–µ–Ω–æ {deleted_count} –∑–∞—Å—Ç–∞—Ä—ñ–ª–∏—Ö embedding'—ñ–≤")
        return deleted_count